{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.024648500Z",
     "start_time": "2023-12-26T12:59:43.302379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, LinearSVR, LinearSVC\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.026610800Z",
     "start_time": "2023-12-26T12:59:47.025613500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Column Selector based on dtype (from lecture)\n",
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selcects the features (numerical, categorical or all)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, select):\n",
    "        \"\"\"\n",
    "        select has to be \"num features\", \"cat features\" or \"all features\"\n",
    "        \"\"\"\n",
    "\n",
    "        if select not in [\"num features\", \"cat features\", \"all features\"]:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        self.select = select\n",
    "        self.num_attr = None\n",
    "        self.cat_attr = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        self.num_attr = list(x.select_dtypes(include=[np.number]).columns)\n",
    "        self.cat_attr = list(x.select_dtypes(exclude=[np.number]).columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"does the transformation\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        if self.select == \"num features\":\n",
    "            x_new = x[self.num_attr].copy()\n",
    "        elif self.select == \"cat features\":\n",
    "            x_new = x[self.cat_attr].copy()\n",
    "        elif self.select == \"all features\":\n",
    "            x_new = x[self.num_attr + self.cat_attr].copy()\n",
    "        else:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"this method is needed, otherwise we cannot use set_ouput\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:12.705507300Z",
     "start_time": "2023-12-26T13:13:12.639960100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('project_1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:28.341985600Z",
     "start_time": "2023-12-26T13:13:28.313685Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>RegularMarij</th>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9217</td>\n",
       "      <td>male</td>\n",
       "      <td>44</td>\n",
       "      <td>40-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>High School</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7325</td>\n",
       "      <td>male</td>\n",
       "      <td>50</td>\n",
       "      <td>50-59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>NeverMarried</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Homosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919</td>\n",
       "      <td>female</td>\n",
       "      <td>59</td>\n",
       "      <td>50-59</td>\n",
       "      <td>718.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>45000-54999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5903</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>40-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0-4999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2808</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "      <td>10-19</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NR  Gender  Age AgeDecade  AgeMonths     Race1  Race3     Education  \\\n",
       "0  9217    male   44     40-49        NaN     White  White   High School   \n",
       "1  7325    male   50     50-59        NaN     White  White  College Grad   \n",
       "2   919  female   59     50-59      718.0     Black    NaN   High School   \n",
       "3  5903  female   40     40-49        NaN     White  White  College Grad   \n",
       "4  2808  female   13     10-19      166.0  Hispanic    NaN           NaN   \n",
       "\n",
       "  MaritalStatus     HHIncome  ...  RegularMarij  AgeRegMarij  HardDrugs  \\\n",
       "0      Divorced  25000-34999  ...            No          NaN        Yes   \n",
       "1  NeverMarried          NaN  ...            No          NaN         No   \n",
       "2       Widowed  45000-54999  ...            No          NaN         No   \n",
       "3      Divorced       0-4999  ...           NaN          NaN        NaN   \n",
       "4           NaN          NaN  ...           NaN          NaN        NaN   \n",
       "\n",
       "  SexEver SexAge  SexNumPartnLife  SexNumPartYear  SameSex SexOrientation  \\\n",
       "0     Yes   17.0             20.0             1.0       No   Heterosexual   \n",
       "1     Yes   24.0              1.0             0.0      Yes     Homosexual   \n",
       "2     Yes   17.0              3.0             1.0       No   Heterosexual   \n",
       "3     NaN    NaN              NaN             NaN      NaN            NaN   \n",
       "4     NaN    NaN              NaN             NaN      NaN            NaN   \n",
       "\n",
       "  PregnantNow  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3          No  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:29.419496500Z",
     "start_time": "2023-12-26T13:13:29.375926300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 71 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   NR                8000 non-null   int64  \n",
      " 1   Gender            8000 non-null   object \n",
      " 2   Age               8000 non-null   int64  \n",
      " 3   AgeDecade         7740 non-null   object \n",
      " 4   AgeMonths         3975 non-null   float64\n",
      " 5   Race1             8000 non-null   object \n",
      " 6   Race3             3994 non-null   object \n",
      " 7   Education         5800 non-null   object \n",
      " 8   MaritalStatus     5806 non-null   object \n",
      " 9   HHIncome          7359 non-null   object \n",
      " 10  HHIncomeMid       7359 non-null   float64\n",
      " 11  Poverty           7423 non-null   float64\n",
      " 12  HomeRooms         7943 non-null   float64\n",
      " 13  HomeOwn           7948 non-null   object \n",
      " 14  Work              6241 non-null   object \n",
      " 15  Weight            7936 non-null   float64\n",
      " 16  Height            7727 non-null   float64\n",
      " 17  BMI               7716 non-null   float64\n",
      " 18  BMICatUnder20yrs  1016 non-null   object \n",
      " 19  BMI_WHO           7690 non-null   object \n",
      " 20  Pulse             6862 non-null   float64\n",
      " 21  BPSysAve          6851 non-null   float64\n",
      " 22  BPDiaAve          6851 non-null   float64\n",
      " 23  BPSys1            6590 non-null   float64\n",
      " 24  BPDia1            6590 non-null   float64\n",
      " 25  BPSys2            6698 non-null   float64\n",
      " 26  BPDia2            6698 non-null   float64\n",
      " 27  BPSys3            6701 non-null   float64\n",
      " 28  BPDia3            6701 non-null   float64\n",
      " 29  Testosterone      3292 non-null   float64\n",
      " 30  DirectChol        6786 non-null   float64\n",
      " 31  UrineVol1         7211 non-null   float64\n",
      " 32  UrineFlow1        6724 non-null   float64\n",
      " 33  UrineVol2         1181 non-null   float64\n",
      " 34  UrineFlow2        1179 non-null   float64\n",
      " 35  Diabetes          7893 non-null   object \n",
      " 36  HealthGen         6034 non-null   object \n",
      " 37  DaysPhysHlthBad   6028 non-null   float64\n",
      " 38  DaysMentHlthBad   6029 non-null   float64\n",
      " 39  LittleInterest    1240 non-null   object \n",
      " 40  Depressed         1130 non-null   object \n",
      " 41  nPregnancies      2081 non-null   float64\n",
      " 42  nBabies           1934 non-null   float64\n",
      " 43  Age1stBaby        1507 non-null   float64\n",
      " 44  SleepHrsNight     6228 non-null   float64\n",
      " 45  SleepTrouble      6241 non-null   object \n",
      " 46  PhysActive        6687 non-null   object \n",
      " 47  PhysActiveDays    3735 non-null   float64\n",
      " 48  TVHrsDay          3886 non-null   object \n",
      " 49  CompHrsDay        3889 non-null   object \n",
      " 50  TVHrsDayChild     507 non-null    float64\n",
      " 51  CompHrsDayChild   507 non-null    float64\n",
      " 52  Alcohol12PlusYr   5266 non-null   object \n",
      " 53  AlcoholDay        3936 non-null   float64\n",
      " 54  AlcoholYear       4734 non-null   float64\n",
      " 55  SmokeNow          2575 non-null   object \n",
      " 56  Smoke100          5809 non-null   object \n",
      " 57  Smoke100n         5809 non-null   object \n",
      " 58  SmokeAge          2478 non-null   float64\n",
      " 59  Marijuana         3979 non-null   object \n",
      " 60  AgeFirstMarij     2339 non-null   float64\n",
      " 61  RegularMarij      3979 non-null   object \n",
      " 62  AgeRegMarij       1086 non-null   float64\n",
      " 63  HardDrugs         4631 non-null   object \n",
      " 64  SexEver           4633 non-null   object \n",
      " 65  SexAge            4464 non-null   float64\n",
      " 66  SexNumPartnLife   4600 non-null   float64\n",
      " 67  SexNumPartYear    3969 non-null   float64\n",
      " 68  SameSex           4634 non-null   object \n",
      " 69  SexOrientation    3898 non-null   object \n",
      " 70  PregnantNow       1383 non-null   object \n",
      "dtypes: float64(39), int64(2), object(30)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:30.064583600Z",
     "start_time": "2023-12-26T13:13:29.977397400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>...</th>\n",
       "      <th>TVHrsDayChild</th>\n",
       "      <th>CompHrsDayChild</th>\n",
       "      <th>AlcoholDay</th>\n",
       "      <th>AlcoholYear</th>\n",
       "      <th>SmokeAge</th>\n",
       "      <th>AgeFirstMarij</th>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>7359.000000</td>\n",
       "      <td>7423.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7936.000000</td>\n",
       "      <td>7727.000000</td>\n",
       "      <td>7716.000000</td>\n",
       "      <td>6862.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>3936.000000</td>\n",
       "      <td>4734.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2339.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>4464.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>3969.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5012.554250</td>\n",
       "      <td>36.667500</td>\n",
       "      <td>421.240000</td>\n",
       "      <td>57291.411877</td>\n",
       "      <td>2.807810</td>\n",
       "      <td>6.249024</td>\n",
       "      <td>71.160622</td>\n",
       "      <td>161.934088</td>\n",
       "      <td>26.673793</td>\n",
       "      <td>73.484115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950690</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>2.931911</td>\n",
       "      <td>75.257710</td>\n",
       "      <td>17.761905</td>\n",
       "      <td>17.050876</td>\n",
       "      <td>17.753223</td>\n",
       "      <td>17.433468</td>\n",
       "      <td>14.243261</td>\n",
       "      <td>1.356513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2887.242281</td>\n",
       "      <td>22.265459</td>\n",
       "      <td>257.011081</td>\n",
       "      <td>33114.586076</td>\n",
       "      <td>1.684218</td>\n",
       "      <td>2.278170</td>\n",
       "      <td>29.010355</td>\n",
       "      <td>20.154350</td>\n",
       "      <td>7.346642</td>\n",
       "      <td>12.090593</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418238</td>\n",
       "      <td>2.560725</td>\n",
       "      <td>3.187721</td>\n",
       "      <td>102.078749</td>\n",
       "      <td>5.170704</td>\n",
       "      <td>3.944924</td>\n",
       "      <td>4.907613</td>\n",
       "      <td>3.695085</td>\n",
       "      <td>47.260997</td>\n",
       "      <td>2.709867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>83.600000</td>\n",
       "      <td>12.890000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2528.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.300000</td>\n",
       "      <td>157.100000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4994.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>166.100000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7504.250000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>89.200000</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>30.930000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>230.700000</td>\n",
       "      <td>200.400000</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NR          Age    AgeMonths    HHIncomeMid      Poverty  \\\n",
       "count   8000.000000  8000.000000  3975.000000    7359.000000  7423.000000   \n",
       "mean    5012.554250    36.667500   421.240000   57291.411877     2.807810   \n",
       "std     2887.242281    22.265459   257.011081   33114.586076     1.684218   \n",
       "min        1.000000     0.000000     0.000000    2500.000000     0.000000   \n",
       "25%     2528.750000    18.000000   204.000000   30000.000000     1.240000   \n",
       "50%     4994.000000    36.000000   420.000000   50000.000000     2.720000   \n",
       "75%     7504.250000    54.000000   619.000000   87500.000000     4.760000   \n",
       "max    10000.000000    80.000000   959.000000  100000.000000     5.000000   \n",
       "\n",
       "         HomeRooms       Weight       Height          BMI        Pulse  ...  \\\n",
       "count  7943.000000  7936.000000  7727.000000  7716.000000  6862.000000  ...   \n",
       "mean      6.249024    71.160622   161.934088    26.673793    73.484115  ...   \n",
       "std       2.278170    29.010355    20.154350     7.346642    12.090593  ...   \n",
       "min       1.000000     2.800000    83.600000    12.890000    40.000000  ...   \n",
       "25%       5.000000    56.300000   157.100000    21.600000    64.000000  ...   \n",
       "50%       6.000000    72.750000   166.100000    26.000000    72.000000  ...   \n",
       "75%       8.000000    89.200000   174.500000    30.930000    82.000000  ...   \n",
       "max      13.000000   230.700000   200.400000    81.250000   134.000000  ...   \n",
       "\n",
       "       TVHrsDayChild  CompHrsDayChild   AlcoholDay  AlcoholYear     SmokeAge  \\\n",
       "count     507.000000       507.000000  3936.000000  4734.000000  2478.000000   \n",
       "mean        1.950690         2.230769     2.931911    75.257710    17.761905   \n",
       "std         1.418238         2.560725     3.187721   102.078749     5.170704   \n",
       "min         0.000000         0.000000     1.000000     0.000000     6.000000   \n",
       "25%         1.000000         0.000000     1.000000     3.000000    15.000000   \n",
       "50%         2.000000         1.000000     2.000000    24.000000    17.000000   \n",
       "75%         3.000000         6.000000     3.000000   104.000000    19.000000   \n",
       "max         6.000000         6.000000    82.000000   364.000000    72.000000   \n",
       "\n",
       "       AgeFirstMarij  AgeRegMarij       SexAge  SexNumPartnLife  \\\n",
       "count    2339.000000  1086.000000  4464.000000      4600.000000   \n",
       "mean       17.050876    17.753223    17.433468        14.243261   \n",
       "std         3.944924     4.907613     3.695085        47.260997   \n",
       "min         1.000000     5.000000     9.000000         0.000000   \n",
       "25%        15.000000    15.000000    15.000000         2.000000   \n",
       "50%        16.000000    17.000000    17.000000         5.000000   \n",
       "75%        19.000000    19.000000    19.000000        12.000000   \n",
       "max        48.000000    52.000000    50.000000      1000.000000   \n",
       "\n",
       "       SexNumPartYear  \n",
       "count     3969.000000  \n",
       "mean         1.356513  \n",
       "std          2.709867  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max         69.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:32.145579500Z",
     "start_time": "2023-12-26T13:13:32.088566700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.11\n",
       "1       1.01\n",
       "2       1.63\n",
       "3       1.47\n",
       "4       1.19\n",
       "        ... \n",
       "7995    1.34\n",
       "7996    1.09\n",
       "7997    1.84\n",
       "7998    1.50\n",
       "7999    1.27\n",
       "Name: DirectChol, Length: 8000, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DirectChol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:21:28.029680600Z",
     "start_time": "2023-12-26T13:21:27.976029900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4697 entries, 0 to 7996\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           4697 non-null   int64  \n",
      " 1   Gender       4697 non-null   object \n",
      " 2   Age          4697 non-null   int64  \n",
      " 3   AgeDecade    4697 non-null   object \n",
      " 4   Race1        4697 non-null   object \n",
      " 5   HHIncome     4697 non-null   object \n",
      " 6   HHIncomeMid  4697 non-null   float64\n",
      " 7   Poverty      4697 non-null   float64\n",
      " 8   HomeRooms    4697 non-null   float64\n",
      " 9   HomeOwn      4697 non-null   object \n",
      " 10  Weight       4697 non-null   float64\n",
      " 11  Height       4697 non-null   float64\n",
      " 12  BMI          4697 non-null   float64\n",
      " 13  BMI_WHO      4697 non-null   object \n",
      " 14  Pulse        4697 non-null   float64\n",
      " 15  BPSysAve     4697 non-null   float64\n",
      " 16  BPDiaAve     4697 non-null   float64\n",
      " 17  BPSys1       4697 non-null   float64\n",
      " 18  BPDia1       4697 non-null   float64\n",
      " 19  BPSys2       4697 non-null   float64\n",
      " 20  BPDia2       4697 non-null   float64\n",
      " 21  BPSys3       4697 non-null   float64\n",
      " 22  BPDia3       4697 non-null   float64\n",
      " 23  DirectChol   4697 non-null   float64\n",
      " 24  UrineVol1    4697 non-null   float64\n",
      " 25  UrineFlow1   4697 non-null   float64\n",
      " 26  Diabetes     4697 non-null   object \n",
      " 27  PhysActive   4697 non-null   object \n",
      "dtypes: float64(18), int64(2), object(8)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10152\\2557067911.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 1500 nas\n",
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:25.110761900Z",
     "start_time": "2023-12-26T13:06:25.092762100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep for regression\n",
    "y_reg = newdf['DirectChol']\n",
    "x_reg = newdf.drop(columns=['DirectChol'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_reg, y_reg, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:27.218119100Z",
     "start_time": "2023-12-26T13:06:27.211118500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = {}  # containing scores and pipeline info\n",
    "\n",
    "# Score Helper Function\n",
    "def display_scores(model_score):\n",
    "    \"\"\"print the list of scores, the mean and the standard deviation\"\"\"\n",
    "    print(\"SCORES OF CROSS VALIDATION:\")\n",
    "    print(np.round(model_score, decimals=1))\n",
    "    print(\"MEAN SCORE: %0.1f\" % model_score.mean())\n",
    "    print(\"STD SCORE: %0.1f\\n\" % model_score.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:28.076527900Z",
     "start_time": "2023-12-26T13:06:28.070513800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lin_reg(x, y):\n",
    "    \"\"\"define model 1\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),  # select numeric attributes\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set toDo better to drop with our dataset?\n",
    "        (\"scaler\", StandardScaler()),  # scale to mean 0 and std 1 toDo: Maybe min_max_scaler?\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation toDo: is this necessary?\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output_reg/lin_reg.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/lin_reg_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/lin_reg_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/lin_reg_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:41.116737700Z",
     "start_time": "2023-12-26T13:06:28.879599400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:50.506166400Z",
     "start_time": "2023-12-26T13:06:50.481624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  2.97  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.34 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.4]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES: 48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "           name  value\n",
      "17    UrineVol1   0.00\n",
      "0            NR  -0.00\n",
      "11       BPSys1  -0.01\n",
      "12       BPDia1   0.01\n",
      "8         Pulse  -0.01\n",
      "41  HomeOwn_Own  -0.01 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "                    name         value\n",
      "39  HHIncome_75000-99999  5.533022e+10\n",
      "40   HHIncome_more 99999  6.346701e+10\n",
      "10              BPDiaAve  9.466151e+10\n",
      "15                BPSys3 -1.110090e+12\n",
      "13                BPSys2 -1.126322e+12\n",
      "9               BPSysAve  2.205099e+12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"output_reg/lin_reg.pkl\")\n",
    "model_1_predictions = joblib.load(\"output_reg/lin_reg_predictions.pkl\")\n",
    "model_1_scores = joblib.load(\"output_reg/lin_reg_scores.pkl\")\n",
    "model_1_time = joblib.load(\"output_reg/lin_reg_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_1_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_1_predictions)))\n",
    "\n",
    "scores[\"model_1\"] = [np.sqrt(-model_1_scores).mean(), model_1, \"lin_reg\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_1\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_1_scores))\n",
    "\n",
    "print(\"USED FEATURES:\", model_1[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_1_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_1[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_1[\"regressor\"].coef_.flatten(),\n",
    "        \"abs_value\": np.abs(model_1[\"regressor\"].coef_).flatten()\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_poly(x, y):\n",
    "    \"\"\"define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),  # select numeric attributes\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set toDo better to drop with our dataset?\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),  # add polynomial features\n",
    "        (\"scaler\", StandardScaler()),  # scale to mean 0 and std 1 toDo: Maybe min_max_scaler?\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation toDo: is this necessary?\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output_reg/lin_reg_poly.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/lin_reg_poly_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/lin_reg_poly_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/lin_reg_poly_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_poly(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  0.91  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.35 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.4]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES: 239\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                     name  value\n",
      "104  HomeRooms UrineFlow1  -0.00\n",
      "209          UrineFlow1^2   0.00\n",
      "88      Poverty UrineVol1  -0.00\n",
      "21                 NR Age   0.01\n",
      "55          Age UrineVol1  -0.01\n",
      "133             BMI Pulse   0.01 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "                   name         value\n",
      "95   HomeRooms BPSysAve -5.562247e+10\n",
      "192       BPSys2 BPDia3  5.590543e+10\n",
      "10             BPSysAve -6.831852e+10\n",
      "163  BPSysAve UrineVol1  8.523152e+10\n",
      "162     BPSysAve BPDia3 -9.677565e+10\n",
      "165          BPDiaAve^2  9.745938e+10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = joblib.load(\"output_reg/lin_reg_poly.pkl\")\n",
    "model_2_predictions = joblib.load(\"output_reg/lin_reg_poly_predictions.pkl\")\n",
    "model_2_scores = joblib.load(\"output_reg/lin_reg_poly_scores.pkl\")\n",
    "model_2_time = joblib.load(\"output_reg/lin_reg_poly_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_2_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_2_predictions)))\n",
    "\n",
    "scores[\"model_2\"] = [np.sqrt(-model_2_scores).mean(), model_2, \"lin_reg_poly\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_2\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_2_scores))\n",
    "\n",
    "print(\"USED FEATURES:\", model_2[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_2_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_2[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_2[\"regressor\"].coef_.flatten(),\n",
    "        \"abs_value\": np.abs(model_2[\"regressor\"].coef_).flatten()\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_2_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_2_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:00.260346400Z",
     "start_time": "2023-12-26T13:07:00.236279800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_reg(x, y):\n",
    "    \"\"\"define model 3\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", DecisionTreeRegressor(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__max_depth\": [8],\n",
    "            \"regressor__min_samples_leaf\": [0.0009],  # [0.0008, 0.0009, 0.001],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output_reg/decision_tree.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output_reg/decision_tree_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/decision_tree_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/decision_tree_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/decision_tree_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:09.003828100Z",
     "start_time": "2023-12-26T13:07:05.541744Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  0.72  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.38 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.4 0.4 0.4]\n",
      "MEAN SCORE: 0.4\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES:  48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                    name  value\n",
      "23      AgeDecade_ 50-59    0.0\n",
      "32  HHIncome_15000-19999    0.0\n",
      "31  HHIncome_10000-14999    0.0\n",
      "28           Race1_Other    0.0\n",
      "27         Race1_Mexican    0.0\n",
      "26        Race1_Hispanic    0.0 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "           name  value\n",
      "6        Height   0.04\n",
      "18   UrineFlow1   0.05\n",
      "19  Gender_male   0.06\n",
      "7           BMI   0.08\n",
      "1           Age   0.10\n",
      "5        Weight   0.31 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__max_depth: 8\n",
      "regressor__min_samples_leaf: 0.0009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = joblib.load(\"output_reg/decision_tree.pkl\")\n",
    "\n",
    "with open(\"output_reg/decision_tree_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions = joblib.load(\"output_reg/decision_tree_predictions.pkl\")\n",
    "model_3_scores = joblib.load(\"output_reg/decision_tree_scores.pkl\")\n",
    "model_3_time = joblib.load(\"output_reg/decision_tree_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_3_predictions)))\n",
    "\n",
    "scores[\"model_3\"] = [np.sqrt(-model_3_scores).mean(), model_3, \"decision_tree\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_3\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_3_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_3[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_3_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_3[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_3[\"regressor\"].feature_importances_,\n",
    "        \"abs_value\": np.abs(model_3[\"regressor\"].feature_importances_)\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_reg(x, y):\n",
    "    \"\"\"Random Forest Regression.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # Set output to pandas\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", RandomForestRegressor(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # Possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__n_estimators\": [100],  # Example: [100, 200]\n",
    "            \"regressor__max_depth\": [None],  # Example: [None, 10, 20]\n",
    "            \"regressor__min_samples_leaf\": [1],  # Example: [1, 2, 4]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # Store model and results\n",
    "    with open(\"output_reg/random_forest.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    with open(\"output_reg/random_forest_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/random_forest_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/random_forest_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/random_forest_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  83.04  sec\n",
      "\n",
      "RMSE: 0.1\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.3 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.3]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES:  48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                    name  value\n",
      "30   HHIncome_ 5000-9999    0.0\n",
      "32  HHIncome_15000-19999    0.0\n",
      "45     BMI_WHO_30.0_plus    0.0\n",
      "25        AgeDecade_ 70+    0.0\n",
      "44  BMI_WHO_25.0_to_29.9    0.0\n",
      "26        Race1_Hispanic    0.0 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "          name  value\n",
      "6       Height   0.05\n",
      "0           NR   0.05\n",
      "18  UrineFlow1   0.05\n",
      "1          Age   0.08\n",
      "7          BMI   0.09\n",
      "5       Weight   0.18 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__max_depth: None\n",
      "regressor__min_samples_leaf: 1\n",
      "regressor__n_estimators: 100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = joblib.load(\"output_reg/random_forest.pkl\")\n",
    "\n",
    "with open(\"output_reg/random_forest_best_params.pkl\", 'rb') as f:\n",
    "    model_4_best_params = pickle.load(f)\n",
    "\n",
    "model_4_predictions = joblib.load(\"output_reg/random_forest_predictions.pkl\")\n",
    "model_4_scores = joblib.load(\"output_reg/random_forest_scores.pkl\")\n",
    "model_4_time = joblib.load(\"output_reg/random_forest_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_4_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_4_predictions)))\n",
    "\n",
    "scores[\"model_4\"] = [np.sqrt(-model_4_scores).mean(), model_4, \"random_forest\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_4\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_4_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_4[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_4_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_4[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_4[\"regressor\"].feature_importances_,\n",
    "        \"abs_value\": np.abs(model_4[\"regressor\"].feature_importances_)\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_4_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_4_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_4_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_reg(x, y):\n",
    "    \"\"\"Support Vector Regression.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # Set output to pandas\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", SVR()),\n",
    "    ])\n",
    "\n",
    "    # Possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__C\": [1, 10, 100],  # Regularization parameter\n",
    "            \"regressor__kernel\": ['rbf'],  # Specifies the kernel type to be used in the algorithm\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # Store model and results\n",
    "    with open(\"output_reg/svr.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    with open(\"output_reg/svr_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/svr_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/svr_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/svr_time.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  11.22  sec\n",
      "\n",
      "RMSE: 0.4\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.4 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.4 0.4 0.4]\n",
      "MEAN SCORE: 0.4\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES:  48\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__C: 100\n",
      "regressor__kernel: rbf\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_5 = joblib.load(\"output_reg/svr.pkl\")\n",
    "\n",
    "with open(\"output_reg/svr_best_params.pkl\", 'rb') as f:\n",
    "    model_5_best_params = pickle.load(f)\n",
    "\n",
    "model_5_predictions = joblib.load(\"output_reg/svr_predictions.pkl\")\n",
    "model_5_scores = joblib.load(\"output_reg/svr_scores.pkl\")\n",
    "model_5_time = joblib.load(\"output_reg/svr_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_5_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_5_predictions)))\n",
    "\n",
    "scores[\"model_5\"] = [np.sqrt(-model_5_scores).mean(), model_5, \"svr\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_5\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_5_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_5[\"regressor\"].n_features_in_)\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_5_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svr_reg(x, y):\n",
    "    \"\"\"Linear Support Vector Regression.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # Set output to pandas\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearSVR(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # Possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__C\": [0.1, 1, 10],  # Regularization parameter\n",
    "            \"regressor__epsilon\": [0, 0.1, 0.2],  # Epsilon parameter in the epsilon-SVR model\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # Store model and results\n",
    "    with open(\"output_reg/linear_svr.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    with open(\"output_reg/linear_svr_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output_reg/linear_svr_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output_reg/linear_svr_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_reg/linear_svr_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "linear_svr_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  8.84  sec\n",
      "\n",
      "RMSE: 0.4\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.67 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.9 0.4 0.7]\n",
      "MEAN SCORE: 0.7\n",
      "STD SCORE: 0.2\n",
      "\n",
      "USED FEATURES:  48\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__C: 0.1\n",
      "regressor__epsilon: 0.2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_6 = joblib.load(\"output_reg/linear_svr.pkl\")\n",
    "\n",
    "with open(\"output_reg/linear_svr_best_params.pkl\", 'rb') as f:\n",
    "    model_6_best_params = pickle.load(f)\n",
    "\n",
    "model_6_predictions = joblib.load(\"output_reg/linear_svr_predictions.pkl\")\n",
    "model_6_scores = joblib.load(\"output_reg/linear_svr_scores.pkl\")\n",
    "model_6_time = joblib.load(\"output_reg/linear_svr_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_6_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_6_predictions)))\n",
    "\n",
    "scores[\"model_6\"] = [np.sqrt(-model_6_scores).mean(), model_6, \"linear_svr\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_6\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_6_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_6[\"regressor\"].n_features_in_)\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_6_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  model_4 \n",
      "\n",
      "BEST MODEL:  random_forest \n",
      "\n",
      "Score:  0.2952179261769861 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select best model from scores\n",
    "best_key = min(scores, key=scores.get)\n",
    "best_scores = scores[best_key]\n",
    "\n",
    "print(\"Key: \", best_key, \"\\n\")\n",
    "print(\"BEST MODEL: \", best_scores[2], \"\\n\")\n",
    "print(\"Score: \", best_scores[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Scores of all models')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot of scores and model names\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar([score[2] for score in scores.values()], [score[0] for score in scores.values()])\n",
    "plt.title(\"Scores of all models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model = joblib.load(f\"output_reg/{best_scores[2]}.pkl\")\n",
    "\n",
    "with open(\"output_reg/best_model_reg.pkl\", \"wb\") as file:\n",
    "    joblib.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5142 entries, 0 to 7997\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           5142 non-null   int64  \n",
      " 1   Age          5142 non-null   int64  \n",
      " 2   HHIncomeMid  5142 non-null   float64\n",
      " 3   Poverty      5142 non-null   float64\n",
      " 4   HomeRooms    5142 non-null   float64\n",
      " 5   Weight       5142 non-null   float64\n",
      " 6   Height       5142 non-null   float64\n",
      " 7   BMI          5142 non-null   float64\n",
      " 8   Pulse        5142 non-null   float64\n",
      " 9   BPSysAve     5142 non-null   float64\n",
      " 10  BPDiaAve     5142 non-null   float64\n",
      " 11  BPSys1       5142 non-null   float64\n",
      " 12  BPDia1       5142 non-null   float64\n",
      " 13  BPSys2       5142 non-null   float64\n",
      " 14  BPDia2       5142 non-null   float64\n",
      " 15  BPSys3       5142 non-null   float64\n",
      " 16  BPDia3       5142 non-null   float64\n",
      " 17  DirectChol   5142 non-null   float64\n",
      " 18  UrineVol1    5142 non-null   float64\n",
      " 19  UrineFlow1   5142 non-null   float64\n",
      " 20  Diabetes     5142 non-null   float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 883.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10152\\326854317.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('project_1_train.csv')\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'Yes', 0, inplace=True)\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'No', 1, inplace=True)\n",
    "df[\"Diabetes\"] = df[\"Diabetes\"].astype(float)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df = df.select_dtypes(include=numerics)\n",
    "\n",
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clas = newdf['Diabetes']\n",
    "\n",
    "x_clas = newdf.drop(columns=['Diabetes'])\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(x_clas, y_clas, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Age</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>BPSysAve</th>\n",
       "      <th>BPDiaAve</th>\n",
       "      <th>BPSys1</th>\n",
       "      <th>BPDia1</th>\n",
       "      <th>BPSys2</th>\n",
       "      <th>BPDia2</th>\n",
       "      <th>BPSys3</th>\n",
       "      <th>BPDia3</th>\n",
       "      <th>DirectChol</th>\n",
       "      <th>UrineVol1</th>\n",
       "      <th>UrineFlow1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>3897</td>\n",
       "      <td>50</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>108.9</td>\n",
       "      <td>180.5</td>\n",
       "      <td>33.43</td>\n",
       "      <td>76.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>291</td>\n",
       "      <td>65</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>175.5</td>\n",
       "      <td>22.01</td>\n",
       "      <td>82.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>5526</td>\n",
       "      <td>24</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.6</td>\n",
       "      <td>176.4</td>\n",
       "      <td>29.80</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>2429</td>\n",
       "      <td>64</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>9723</td>\n",
       "      <td>57</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>169.3</td>\n",
       "      <td>24.70</td>\n",
       "      <td>48.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>407</td>\n",
       "      <td>22</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.8</td>\n",
       "      <td>162.0</td>\n",
       "      <td>24.31</td>\n",
       "      <td>62.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>8296</td>\n",
       "      <td>73</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>169.9</td>\n",
       "      <td>28.70</td>\n",
       "      <td>78.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>5615</td>\n",
       "      <td>50</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.2</td>\n",
       "      <td>175.5</td>\n",
       "      <td>30.60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>6515</td>\n",
       "      <td>22</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>154.9</td>\n",
       "      <td>31.70</td>\n",
       "      <td>70.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>2117</td>\n",
       "      <td>38</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>163.9</td>\n",
       "      <td>24.87</td>\n",
       "      <td>64.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4113 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NR  Age  HHIncomeMid  Poverty  HomeRooms  Weight  Height    BMI  \\\n",
       "5211  3897   50      87500.0     3.63       10.0   108.9   180.5  33.43   \n",
       "1475   291   65     100000.0     5.00        7.0    67.8   175.5  22.01   \n",
       "6290  5526   24      50000.0     2.33        4.0    92.6   176.4  29.80   \n",
       "7967  2429   64     100000.0     5.00       10.0    98.0   176.0  31.64   \n",
       "3271  9723   57      70000.0     3.13        5.0    70.8   169.3  24.70   \n",
       "...    ...  ...          ...      ...        ...     ...     ...    ...   \n",
       "2412   407   22      60000.0     1.39        5.0    63.8   162.0  24.31   \n",
       "6275  8296   73      87500.0     2.20        5.0    82.9   169.9  28.70   \n",
       "2020  5615   50      87500.0     5.00        7.0    94.2   175.5  30.60   \n",
       "5340  6515   22      30000.0     1.67        5.0    76.1   154.9  31.70   \n",
       "5530  2117   38     100000.0     4.99        4.0    66.8   163.9  24.87   \n",
       "\n",
       "      Pulse  BPSysAve  BPDiaAve  BPSys1  BPDia1  BPSys2  BPDia2  BPSys3  \\\n",
       "5211   76.0     125.0      72.0   124.0    70.0   128.0    72.0   122.0   \n",
       "1475   82.0     114.0      53.0   112.0    54.0   114.0    52.0   114.0   \n",
       "6290   70.0     102.0      56.0   102.0    58.0   102.0    56.0   102.0   \n",
       "7967   66.0     116.0      67.0   114.0    64.0   116.0    66.0   116.0   \n",
       "3271   48.0     113.0      65.0   114.0    66.0   116.0    66.0   110.0   \n",
       "...     ...       ...       ...     ...     ...     ...     ...     ...   \n",
       "2412   62.0     119.0      49.0   118.0    46.0   120.0    46.0   118.0   \n",
       "6275   78.0     123.0      65.0   124.0    62.0   126.0    62.0   120.0   \n",
       "2020   78.0     110.0      79.0   112.0    84.0   108.0    80.0   112.0   \n",
       "5340   70.0     119.0      51.0   116.0    50.0   120.0    48.0   118.0   \n",
       "5530   64.0     107.0      70.0   102.0    70.0   106.0    70.0   108.0   \n",
       "\n",
       "      BPDia3  DirectChol  UrineVol1  UrineFlow1  \n",
       "5211    72.0        1.06       64.0       0.753  \n",
       "1475    54.0        1.60       21.0       0.368  \n",
       "6290    56.0        1.06       33.0       0.068  \n",
       "7967    68.0        0.93       67.0       0.677  \n",
       "3271    64.0        1.14       97.0       0.890  \n",
       "...      ...         ...        ...         ...  \n",
       "2412    52.0        2.12      242.0       1.485  \n",
       "6275    68.0        1.06       23.0       0.299  \n",
       "2020    78.0        0.85       56.0       0.339  \n",
       "5340    54.0        1.34       54.0       0.551  \n",
       "5530    70.0        1.53      212.0       0.951  \n",
       "\n",
       "[4113 rows x 20 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "1.0    3765\n",
       "0.0     348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority class\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample_data(X_train_c, y_train_c):\n",
    "    \"\"\"\n",
    "    Upsample the minority class in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train_c (DataFrame): The features of the training data.\n",
    "    y_train_c (Series): The target of the training data, indicating the presence of Diabetes.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame, Series: The upsampled features and target data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine the features and target into a single DataFrame for resampling\n",
    "    train_data = pd.concat([X_train_c, y_train_c], axis=1)\n",
    "\n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = train_data[train_data.Diabetes == 1.0]\n",
    "    minority_class = train_data[train_data.Diabetes == 0.0]\n",
    "\n",
    "    # Upsample the minority class\n",
    "    minority_class_upsampled = resample(minority_class,\n",
    "                                        replace=True,                  # sample with replacement\n",
    "                                        n_samples=len(majority_class), # to match majority class size\n",
    "                                        random_state=123)              # for reproducible results\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    upsampled_data = pd.concat([majority_class, minority_class_upsampled])\n",
    "\n",
    "    # Separate features and target\n",
    "    X_train_upsampled = upsampled_data.drop('Diabetes', axis=1)\n",
    "    y_train_upsampled = upsampled_data['Diabetes']\n",
    "\n",
    "    return X_train_upsampled, y_train_upsampled\n",
    "\n",
    "X_train_c, y_train_c = upsample_data(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "1.0    3765\n",
       "0.0    3765\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}  # containing scores and pipeline info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(x, y):\n",
    "    \"\"\"Define model 1\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"pca\", PCA(n_components=0.9)),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\")),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # binary fit for each label\n",
    "        {\n",
    "            \"classifier__multi_class\": [\"ovr\"],  # binary fit for each label\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"lbfgs\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        },\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"classifier__multi_class\": [\"multinomial\"],  # softmax regression\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"saga\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"output_clf/log_reg_cl.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output_clf/log_reg_cl_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions_cv, filename=\"output_clf/log_reg_cl_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_clf/log_reg_cl_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  1.17  sec\n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[2933  832]\n",
      " [1062 2703]] \n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.78      0.76      3765\n",
      "         1.0       0.76      0.72      0.74      3765\n",
      "\n",
      "    accuracy                           0.75      7530\n",
      "   macro avg       0.75      0.75      0.75      7530\n",
      "weighted avg       0.75      0.75      0.75      7530\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.75 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 0.1\n",
      "classifier__multi_class: ovr\n",
      "classifier__penalty: l2\n",
      "classifier__solver: lbfgs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"output_clf/log_reg_cl.pkl\")\n",
    "\n",
    "with open(\"output_clf/log_reg_cl_best_params.pkl\", 'rb') as f:\n",
    "    model_1_best_params = pickle.load(f)\n",
    "\n",
    "model_1_predictions_cv = joblib.load(\"output_clf/log_reg_cl_predictions_cv.pkl\")\n",
    "model_1_time = joblib.load(\"output_clf/log_reg_cl_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_1_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_1_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_1_predictions_cv))\n",
    "\n",
    "model_1_score = f1_score(y_train_c, model_1_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_1\"] = [model_1_score, model_1, \"log_reg_cl\"]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_1_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_1_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_poly(x, y):\n",
    "    \"\"\"Define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"pca\", PCA(n_components=0.9)),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\")),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # binary fit for each label\n",
    "        {\n",
    "            \"classifier__multi_class\": [\"ovr\"],  # binary fit for each label\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"lbfgs\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        },\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"classifier__multi_class\": [\"multinomial\"],  # softmax regression\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"saga\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"output_clf/log_reg_poly_cl.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output_clf/log_reg_poly_cl_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions_cv, filename=\"output_clf/log_reg_poly_cl_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_clf/log_reg_poly_cl_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_poly(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  4.29  sec\n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[2870  895]\n",
      " [1045 2720]] \n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.75      3765\n",
      "         1.0       0.75      0.72      0.74      3765\n",
      "\n",
      "    accuracy                           0.74      7530\n",
      "   macro avg       0.74      0.74      0.74      7530\n",
      "weighted avg       0.74      0.74      0.74      7530\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.74 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 0.1\n",
      "classifier__multi_class: ovr\n",
      "classifier__penalty: l2\n",
      "classifier__solver: lbfgs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = joblib.load(\"output_clf/log_reg_poly_cl.pkl\")\n",
    "\n",
    "with open(\"output_clf/log_reg_poly_cl_best_params.pkl\", 'rb') as f:\n",
    "    model_2_best_params = pickle.load(f)\n",
    "\n",
    "model_2_predictions_cv = joblib.load(\"output_clf/log_reg_poly_cl_predictions_cv.pkl\")\n",
    "model_2_time = joblib.load(\"output_clf/log_reg_poly_cl_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_2_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_2_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_2_predictions_cv))\n",
    "\n",
    "model_2_score = f1_score(y_train_c, model_2_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_2\"] = [model_2_score, model_2, \"log_reg_poly_cl\"]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_2_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_2_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_clf(X, y):\n",
    "    \"\"\"Support Vector Machine Classification.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"pca\", PCA(n_components=0.9)),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\")),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"classifier\", SVC(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # Possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"classifier__C\": [0.1, 1, 10],  # Regularization parameter\n",
    "            \"classifier__kernel\": [\"rbf\", \"poly\", \"sigmoid\"],  # Specifies the kernel type\n",
    "            \"classifier__gamma\": [\"scale\", \"auto\"],  # Kernel coefficient\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(X, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    # Attention: Use a clone of the model for cross-validation predictions\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, X, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # Store model and results\n",
    "    joblib.dump(model, filename=\"output_clf/svc_clf.pkl\")\n",
    "    with open(\"output_clf/svc_clf_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "    joblib.dump(model_predictions_cv, filename=\"output_clf/svc_clf_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_clf/svc_clf_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  87.26  sec\n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[3523  242]\n",
      " [ 707 3058]] \n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.94      0.88      3765\n",
      "         1.0       0.93      0.81      0.87      3765\n",
      "\n",
      "    accuracy                           0.87      7530\n",
      "   macro avg       0.88      0.87      0.87      7530\n",
      "weighted avg       0.88      0.87      0.87      7530\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.87 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 10\n",
      "classifier__gamma: scale\n",
      "classifier__kernel: rbf\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = joblib.load(\"output_clf/svc_clf.pkl\")\n",
    "\n",
    "with open(\"output_clf/svc_clf_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions_cv = joblib.load(\"output_clf/svc_clf_predictions_cv.pkl\")\n",
    "model_3_time = joblib.load(\"output_clf/svc_clf_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_3_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_3_predictions_cv))\n",
    "\n",
    "model_3_score = f1_score(y_train_c, model_3_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_3\"] = [model_3_score, model_3, \"svc_clf\"]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_3_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svc_clf(X, y):\n",
    "    \"\"\"Linear Support Vector Machine Classification.\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"pca\", PCA(n_components=0.9)),\n",
    "    ])\n",
    "\n",
    "    # Categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\")),\n",
    "    ])\n",
    "\n",
    "    # Combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # Define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"classifier\", LinearSVC(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # Possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__loss\": [\"squared_hinge\"],  # Typically used for linear SVM\n",
    "            \"classifier__C\": [0.1, 1, 10],  # Regularization parameter\n",
    "            \"classifier__dual\": [True, False],  # Dual or primal formulation\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=5, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(X, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    # Attention: Use a clone of the model for cross-validation predictions\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, X, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # Store model and results\n",
    "    joblib.dump(model, filename=\"output_clf/linear_svc_clf.pkl\")\n",
    "    with open(\"output_clf/linear_svc_clf_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "    joblib.dump(model_predictions_cv, filename=\"output_clf/linear_svc_clf_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output_clf/linear_svc_clf_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_clf(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  2.42  sec\n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[2952  813]\n",
      " [1091 2674]] \n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.78      0.76      3765\n",
      "         1.0       0.77      0.71      0.74      3765\n",
      "\n",
      "    accuracy                           0.75      7530\n",
      "   macro avg       0.75      0.75      0.75      7530\n",
      "weighted avg       0.75      0.75      0.75      7530\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.75 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 0.1\n",
      "classifier__dual: True\n",
      "classifier__loss: squared_hinge\n",
      "classifier__penalty: l2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = joblib.load(\"output_clf/linear_svc_clf.pkl\")\n",
    "\n",
    "with open(\"output_clf/linear_svc_clf_best_params.pkl\", 'rb') as f:\n",
    "    model_4_best_params = pickle.load(f)\n",
    "\n",
    "model_4_predictions_cv = joblib.load(\"output_clf/linear_svc_clf_predictions_cv.pkl\")\n",
    "model_4_time = joblib.load(\"output_clf/linear_svc_clf_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_4_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_4_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_4_predictions_cv))\n",
    "\n",
    "model_4_score = f1_score(y_train_c, model_4_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_4\"] = [model_4_score, model_4, \"linear_svc_clf\"]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_4_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_4_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
