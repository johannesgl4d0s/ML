{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.024648500Z",
     "start_time": "2023-12-26T12:59:43.302379Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selcects the features (numerical, categorical or all)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, select):\n",
    "        \"\"\"\n",
    "        select has to be \"num features\", \"cat features\" or \"all features\"\n",
    "        \"\"\"\n",
    "\n",
    "        if select not in [\"num features\", \"cat features\", \"all features\"]:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        self.select = select\n",
    "        self.num_attr = None\n",
    "        self.cat_attr = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        self.num_attr = list(x.select_dtypes(include=[np.number]).columns)\n",
    "        self.cat_attr = list(x.select_dtypes(exclude=[np.number]).columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"does the transformation\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        if self.select == \"num features\":\n",
    "            x_new = x[self.num_attr].copy()\n",
    "        elif self.select == \"cat features\":\n",
    "            x_new = x[self.cat_attr].copy()\n",
    "        elif self.select == \"all features\":\n",
    "            x_new = x[self.num_attr + self.cat_attr].copy()\n",
    "        else:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"this method is needed, otherwise we cannot use set_ouput\"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.026610800Z",
     "start_time": "2023-12-26T12:59:47.025613500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class NumAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Adds new numeric features\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"NumAttributesAdder needs Pandas Dataframe!\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod  # static because in transform self is not used\n",
    "    def transform(_self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"does the transformation\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"NumAttributesAdder needs Pandas Dataframe!\")\n",
    "\n",
    "        x_new = x.copy()\n",
    "        x_new[\"rooms_per_household\"] = x_new[\"total_rooms\"] / x_new[\"households\"]\n",
    "        x_new[\"rooms_per_household\"].clip(lower=1, inplace=True)  # hard to find an upper value (consider touristic region with hotels only)\n",
    "        x_new[\"population_per_household\"] = x_new[\"population\"] / x_new[\"households\"]\n",
    "        x_new[\"population_per_household\"].clip(0, 10, inplace=True)\n",
    "        x_new[\"bedrooms_per_room\"] = x_new[\"total_bedrooms\"] / x_new[\"total_rooms\"]\n",
    "        x_new[\"bedrooms_per_room\"].clip(0, 1, inplace=True)\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"this method is needed, otherwise we cannot use set_ouput\"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.026610800Z",
     "start_time": "2023-12-26T12:59:47.025613500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df = pd.read_csv('project_1_train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:12.705507300Z",
     "start_time": "2023-12-26T13:13:12.639960100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "     NR  Gender  Age AgeDecade  AgeMonths     Race1  Race3     Education  \\\n0  9217    male   44     40-49        NaN     White  White   High School   \n1  7325    male   50     50-59        NaN     White  White  College Grad   \n2   919  female   59     50-59      718.0     Black    NaN   High School   \n3  5903  female   40     40-49        NaN     White  White  College Grad   \n4  2808  female   13     10-19      166.0  Hispanic    NaN           NaN   \n\n  MaritalStatus     HHIncome  ...  RegularMarij  AgeRegMarij  HardDrugs  \\\n0      Divorced  25000-34999  ...            No          NaN        Yes   \n1  NeverMarried          NaN  ...            No          NaN         No   \n2       Widowed  45000-54999  ...            No          NaN         No   \n3      Divorced       0-4999  ...           NaN          NaN        NaN   \n4           NaN          NaN  ...           NaN          NaN        NaN   \n\n  SexEver SexAge  SexNumPartnLife  SexNumPartYear  SameSex SexOrientation  \\\n0     Yes   17.0             20.0             1.0       No   Heterosexual   \n1     Yes   24.0              1.0             0.0      Yes     Homosexual   \n2     Yes   17.0              3.0             1.0       No   Heterosexual   \n3     NaN    NaN              NaN             NaN      NaN            NaN   \n4     NaN    NaN              NaN             NaN      NaN            NaN   \n\n  PregnantNow  \n0         NaN  \n1         NaN  \n2         NaN  \n3          No  \n4         NaN  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NR</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>AgeDecade</th>\n      <th>AgeMonths</th>\n      <th>Race1</th>\n      <th>Race3</th>\n      <th>Education</th>\n      <th>MaritalStatus</th>\n      <th>HHIncome</th>\n      <th>...</th>\n      <th>RegularMarij</th>\n      <th>AgeRegMarij</th>\n      <th>HardDrugs</th>\n      <th>SexEver</th>\n      <th>SexAge</th>\n      <th>SexNumPartnLife</th>\n      <th>SexNumPartYear</th>\n      <th>SameSex</th>\n      <th>SexOrientation</th>\n      <th>PregnantNow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9217</td>\n      <td>male</td>\n      <td>44</td>\n      <td>40-49</td>\n      <td>NaN</td>\n      <td>White</td>\n      <td>White</td>\n      <td>High School</td>\n      <td>Divorced</td>\n      <td>25000-34999</td>\n      <td>...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>17.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Heterosexual</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7325</td>\n      <td>male</td>\n      <td>50</td>\n      <td>50-59</td>\n      <td>NaN</td>\n      <td>White</td>\n      <td>White</td>\n      <td>College Grad</td>\n      <td>NeverMarried</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>Homosexual</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>919</td>\n      <td>female</td>\n      <td>59</td>\n      <td>50-59</td>\n      <td>718.0</td>\n      <td>Black</td>\n      <td>NaN</td>\n      <td>High School</td>\n      <td>Widowed</td>\n      <td>45000-54999</td>\n      <td>...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Heterosexual</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5903</td>\n      <td>female</td>\n      <td>40</td>\n      <td>40-49</td>\n      <td>NaN</td>\n      <td>White</td>\n      <td>White</td>\n      <td>College Grad</td>\n      <td>Divorced</td>\n      <td>0-4999</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2808</td>\n      <td>female</td>\n      <td>13</td>\n      <td>10-19</td>\n      <td>166.0</td>\n      <td>Hispanic</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:28.341985600Z",
     "start_time": "2023-12-26T13:13:28.313685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 71 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   NR                8000 non-null   int64  \n",
      " 1   Gender            8000 non-null   object \n",
      " 2   Age               8000 non-null   int64  \n",
      " 3   AgeDecade         7740 non-null   object \n",
      " 4   AgeMonths         3975 non-null   float64\n",
      " 5   Race1             8000 non-null   object \n",
      " 6   Race3             3994 non-null   object \n",
      " 7   Education         5800 non-null   object \n",
      " 8   MaritalStatus     5806 non-null   object \n",
      " 9   HHIncome          7359 non-null   object \n",
      " 10  HHIncomeMid       7359 non-null   float64\n",
      " 11  Poverty           7423 non-null   float64\n",
      " 12  HomeRooms         7943 non-null   float64\n",
      " 13  HomeOwn           7948 non-null   object \n",
      " 14  Work              6241 non-null   object \n",
      " 15  Weight            7936 non-null   float64\n",
      " 16  Height            7727 non-null   float64\n",
      " 17  BMI               7716 non-null   float64\n",
      " 18  BMICatUnder20yrs  1016 non-null   object \n",
      " 19  BMI_WHO           7690 non-null   object \n",
      " 20  Pulse             6862 non-null   float64\n",
      " 21  BPSysAve          6851 non-null   float64\n",
      " 22  BPDiaAve          6851 non-null   float64\n",
      " 23  BPSys1            6590 non-null   float64\n",
      " 24  BPDia1            6590 non-null   float64\n",
      " 25  BPSys2            6698 non-null   float64\n",
      " 26  BPDia2            6698 non-null   float64\n",
      " 27  BPSys3            6701 non-null   float64\n",
      " 28  BPDia3            6701 non-null   float64\n",
      " 29  Testosterone      3292 non-null   float64\n",
      " 30  DirectChol        6786 non-null   float64\n",
      " 31  UrineVol1         7211 non-null   float64\n",
      " 32  UrineFlow1        6724 non-null   float64\n",
      " 33  UrineVol2         1181 non-null   float64\n",
      " 34  UrineFlow2        1179 non-null   float64\n",
      " 35  Diabetes          7893 non-null   object \n",
      " 36  HealthGen         6034 non-null   object \n",
      " 37  DaysPhysHlthBad   6028 non-null   float64\n",
      " 38  DaysMentHlthBad   6029 non-null   float64\n",
      " 39  LittleInterest    1240 non-null   object \n",
      " 40  Depressed         1130 non-null   object \n",
      " 41  nPregnancies      2081 non-null   float64\n",
      " 42  nBabies           1934 non-null   float64\n",
      " 43  Age1stBaby        1507 non-null   float64\n",
      " 44  SleepHrsNight     6228 non-null   float64\n",
      " 45  SleepTrouble      6241 non-null   object \n",
      " 46  PhysActive        6687 non-null   object \n",
      " 47  PhysActiveDays    3735 non-null   float64\n",
      " 48  TVHrsDay          3886 non-null   object \n",
      " 49  CompHrsDay        3889 non-null   object \n",
      " 50  TVHrsDayChild     507 non-null    float64\n",
      " 51  CompHrsDayChild   507 non-null    float64\n",
      " 52  Alcohol12PlusYr   5266 non-null   object \n",
      " 53  AlcoholDay        3936 non-null   float64\n",
      " 54  AlcoholYear       4734 non-null   float64\n",
      " 55  SmokeNow          2575 non-null   object \n",
      " 56  Smoke100          5809 non-null   object \n",
      " 57  Smoke100n         5809 non-null   object \n",
      " 58  SmokeAge          2478 non-null   float64\n",
      " 59  Marijuana         3979 non-null   object \n",
      " 60  AgeFirstMarij     2339 non-null   float64\n",
      " 61  RegularMarij      3979 non-null   object \n",
      " 62  AgeRegMarij       1086 non-null   float64\n",
      " 63  HardDrugs         4631 non-null   object \n",
      " 64  SexEver           4633 non-null   object \n",
      " 65  SexAge            4464 non-null   float64\n",
      " 66  SexNumPartnLife   4600 non-null   float64\n",
      " 67  SexNumPartYear    3969 non-null   float64\n",
      " 68  SameSex           4634 non-null   object \n",
      " 69  SexOrientation    3898 non-null   object \n",
      " 70  PregnantNow       1383 non-null   object \n",
      "dtypes: float64(39), int64(2), object(30)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:29.419496500Z",
     "start_time": "2023-12-26T13:13:29.375926300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                 NR          Age    AgeMonths    HHIncomeMid      Poverty  \\\ncount   8000.000000  8000.000000  3975.000000    7359.000000  7423.000000   \nmean    5012.554250    36.667500   421.240000   57291.411877     2.807810   \nstd     2887.242281    22.265459   257.011081   33114.586076     1.684218   \nmin        1.000000     0.000000     0.000000    2500.000000     0.000000   \n25%     2528.750000    18.000000   204.000000   30000.000000     1.240000   \n50%     4994.000000    36.000000   420.000000   50000.000000     2.720000   \n75%     7504.250000    54.000000   619.000000   87500.000000     4.760000   \nmax    10000.000000    80.000000   959.000000  100000.000000     5.000000   \n\n         HomeRooms       Weight       Height          BMI        Pulse  ...  \\\ncount  7943.000000  7936.000000  7727.000000  7716.000000  6862.000000  ...   \nmean      6.249024    71.160622   161.934088    26.673793    73.484115  ...   \nstd       2.278170    29.010355    20.154350     7.346642    12.090593  ...   \nmin       1.000000     2.800000    83.600000    12.890000    40.000000  ...   \n25%       5.000000    56.300000   157.100000    21.600000    64.000000  ...   \n50%       6.000000    72.750000   166.100000    26.000000    72.000000  ...   \n75%       8.000000    89.200000   174.500000    30.930000    82.000000  ...   \nmax      13.000000   230.700000   200.400000    81.250000   134.000000  ...   \n\n       TVHrsDayChild  CompHrsDayChild   AlcoholDay  AlcoholYear     SmokeAge  \\\ncount     507.000000       507.000000  3936.000000  4734.000000  2478.000000   \nmean        1.950690         2.230769     2.931911    75.257710    17.761905   \nstd         1.418238         2.560725     3.187721   102.078749     5.170704   \nmin         0.000000         0.000000     1.000000     0.000000     6.000000   \n25%         1.000000         0.000000     1.000000     3.000000    15.000000   \n50%         2.000000         1.000000     2.000000    24.000000    17.000000   \n75%         3.000000         6.000000     3.000000   104.000000    19.000000   \nmax         6.000000         6.000000    82.000000   364.000000    72.000000   \n\n       AgeFirstMarij  AgeRegMarij       SexAge  SexNumPartnLife  \\\ncount    2339.000000  1086.000000  4464.000000      4600.000000   \nmean       17.050876    17.753223    17.433468        14.243261   \nstd         3.944924     4.907613     3.695085        47.260997   \nmin         1.000000     5.000000     9.000000         0.000000   \n25%        15.000000    15.000000    15.000000         2.000000   \n50%        16.000000    17.000000    17.000000         5.000000   \n75%        19.000000    19.000000    19.000000        12.000000   \nmax        48.000000    52.000000    50.000000      1000.000000   \n\n       SexNumPartYear  \ncount     3969.000000  \nmean         1.356513  \nstd          2.709867  \nmin          0.000000  \n25%          1.000000  \n50%          1.000000  \n75%          1.000000  \nmax         69.000000  \n\n[8 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NR</th>\n      <th>Age</th>\n      <th>AgeMonths</th>\n      <th>HHIncomeMid</th>\n      <th>Poverty</th>\n      <th>HomeRooms</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>BMI</th>\n      <th>Pulse</th>\n      <th>...</th>\n      <th>TVHrsDayChild</th>\n      <th>CompHrsDayChild</th>\n      <th>AlcoholDay</th>\n      <th>AlcoholYear</th>\n      <th>SmokeAge</th>\n      <th>AgeFirstMarij</th>\n      <th>AgeRegMarij</th>\n      <th>SexAge</th>\n      <th>SexNumPartnLife</th>\n      <th>SexNumPartYear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8000.000000</td>\n      <td>8000.000000</td>\n      <td>3975.000000</td>\n      <td>7359.000000</td>\n      <td>7423.000000</td>\n      <td>7943.000000</td>\n      <td>7936.000000</td>\n      <td>7727.000000</td>\n      <td>7716.000000</td>\n      <td>6862.000000</td>\n      <td>...</td>\n      <td>507.000000</td>\n      <td>507.000000</td>\n      <td>3936.000000</td>\n      <td>4734.000000</td>\n      <td>2478.000000</td>\n      <td>2339.000000</td>\n      <td>1086.000000</td>\n      <td>4464.000000</td>\n      <td>4600.000000</td>\n      <td>3969.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5012.554250</td>\n      <td>36.667500</td>\n      <td>421.240000</td>\n      <td>57291.411877</td>\n      <td>2.807810</td>\n      <td>6.249024</td>\n      <td>71.160622</td>\n      <td>161.934088</td>\n      <td>26.673793</td>\n      <td>73.484115</td>\n      <td>...</td>\n      <td>1.950690</td>\n      <td>2.230769</td>\n      <td>2.931911</td>\n      <td>75.257710</td>\n      <td>17.761905</td>\n      <td>17.050876</td>\n      <td>17.753223</td>\n      <td>17.433468</td>\n      <td>14.243261</td>\n      <td>1.356513</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2887.242281</td>\n      <td>22.265459</td>\n      <td>257.011081</td>\n      <td>33114.586076</td>\n      <td>1.684218</td>\n      <td>2.278170</td>\n      <td>29.010355</td>\n      <td>20.154350</td>\n      <td>7.346642</td>\n      <td>12.090593</td>\n      <td>...</td>\n      <td>1.418238</td>\n      <td>2.560725</td>\n      <td>3.187721</td>\n      <td>102.078749</td>\n      <td>5.170704</td>\n      <td>3.944924</td>\n      <td>4.907613</td>\n      <td>3.695085</td>\n      <td>47.260997</td>\n      <td>2.709867</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2500.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.800000</td>\n      <td>83.600000</td>\n      <td>12.890000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2528.750000</td>\n      <td>18.000000</td>\n      <td>204.000000</td>\n      <td>30000.000000</td>\n      <td>1.240000</td>\n      <td>5.000000</td>\n      <td>56.300000</td>\n      <td>157.100000</td>\n      <td>21.600000</td>\n      <td>64.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4994.000000</td>\n      <td>36.000000</td>\n      <td>420.000000</td>\n      <td>50000.000000</td>\n      <td>2.720000</td>\n      <td>6.000000</td>\n      <td>72.750000</td>\n      <td>166.100000</td>\n      <td>26.000000</td>\n      <td>72.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>24.000000</td>\n      <td>17.000000</td>\n      <td>16.000000</td>\n      <td>17.000000</td>\n      <td>17.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7504.250000</td>\n      <td>54.000000</td>\n      <td>619.000000</td>\n      <td>87500.000000</td>\n      <td>4.760000</td>\n      <td>8.000000</td>\n      <td>89.200000</td>\n      <td>174.500000</td>\n      <td>30.930000</td>\n      <td>82.000000</td>\n      <td>...</td>\n      <td>3.000000</td>\n      <td>6.000000</td>\n      <td>3.000000</td>\n      <td>104.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>12.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10000.000000</td>\n      <td>80.000000</td>\n      <td>959.000000</td>\n      <td>100000.000000</td>\n      <td>5.000000</td>\n      <td>13.000000</td>\n      <td>230.700000</td>\n      <td>200.400000</td>\n      <td>81.250000</td>\n      <td>134.000000</td>\n      <td>...</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>82.000000</td>\n      <td>364.000000</td>\n      <td>72.000000</td>\n      <td>48.000000</td>\n      <td>52.000000</td>\n      <td>50.000000</td>\n      <td>1000.000000</td>\n      <td>69.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:30.064583600Z",
     "start_time": "2023-12-26T13:13:29.977397400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0       1.11\n1       1.01\n2       1.63\n3       1.47\n4       1.19\n        ... \n7995    1.34\n7996    1.09\n7997    1.84\n7998    1.50\n7999    1.27\nName: DirectChol, Length: 8000, dtype: float64"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DirectChol']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:32.145579500Z",
     "start_time": "2023-12-26T13:13:32.088566700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Applying the condition, but leave nan for now\n",
    "# df['Diabetes'].mask(df['Diabetes'] == 'Yes', 0, inplace=True)\n",
    "# df['Diabetes'].mask(df['Diabetes'] == 'No', 1, inplace=True)\n",
    "# df[\"Diabetes\"] = df[\"Diabetes\"].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:12:12.047948200Z",
     "start_time": "2023-12-26T13:12:12.024314400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#df[\"Diabetes\"].info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:12:13.673007200Z",
     "start_time": "2023-12-26T13:12:13.657554200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "#\n",
    "# newdf = df.select_dtypes(include=numerics)\n",
    "#\n",
    "# newdf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:00:07.716938200Z",
     "start_time": "2023-12-26T13:00:07.701938900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4697 entries, 0 to 7996\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           4697 non-null   int64  \n",
      " 1   Gender       4697 non-null   object \n",
      " 2   Age          4697 non-null   int64  \n",
      " 3   AgeDecade    4697 non-null   object \n",
      " 4   Race1        4697 non-null   object \n",
      " 5   HHIncome     4697 non-null   object \n",
      " 6   HHIncomeMid  4697 non-null   float64\n",
      " 7   Poverty      4697 non-null   float64\n",
      " 8   HomeRooms    4697 non-null   float64\n",
      " 9   HomeOwn      4697 non-null   object \n",
      " 10  Weight       4697 non-null   float64\n",
      " 11  Height       4697 non-null   float64\n",
      " 12  BMI          4697 non-null   float64\n",
      " 13  BMI_WHO      4697 non-null   object \n",
      " 14  Pulse        4697 non-null   float64\n",
      " 15  BPSysAve     4697 non-null   float64\n",
      " 16  BPDiaAve     4697 non-null   float64\n",
      " 17  BPSys1       4697 non-null   float64\n",
      " 18  BPDia1       4697 non-null   float64\n",
      " 19  BPSys2       4697 non-null   float64\n",
      " 20  BPDia2       4697 non-null   float64\n",
      " 21  BPSys3       4697 non-null   float64\n",
      " 22  BPDia3       4697 non-null   float64\n",
      " 23  DirectChol   4697 non-null   float64\n",
      " 24  UrineVol1    4697 non-null   float64\n",
      " 25  UrineFlow1   4697 non-null   float64\n",
      " 26  Diabetes     4697 non-null   object \n",
      " 27  PhysActive   4697 non-null   object \n",
      "dtypes: float64(18), int64(2), object(8)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_29744\\3290329661.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:21:28.029680600Z",
     "start_time": "2023-12-26T13:21:27.976029900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "y_reg = newdf['DirectChol']\n",
    "\n",
    "x_reg = newdf.drop(columns=['DirectChol'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:25.110761900Z",
     "start_time": "2023-12-26T13:06:25.092762100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_reg, y_reg, test_size=0.2, random_state=123)\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(x_clas, y_clas, test_size=0.2, random_state=123)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:26.214680900Z",
     "start_time": "2023-12-26T13:06:26.192647700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "scores = {}\n",
    "def display_scores(model_score):\n",
    "    \"\"\"print the list of scores, the mean and the standard deviation\"\"\"\n",
    "    print(\"SCORES OF CROSS VALIDATION:\")\n",
    "    print(np.round(model_score, decimals=1))\n",
    "    print(\"MEAN SCORE: %0.1f\" % model_score.mean())\n",
    "    print(\"STD SCORE: %0.1f\\n\" % model_score.std())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:27.218119100Z",
     "start_time": "2023-12-26T13:06:27.211118500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def lin_reg(x, y):\n",
    "    \"\"\"define model 1\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),  # select numeric attributes\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set toDo better to drop with our dataset?\n",
    "        (\"scaler\", StandardScaler()),  # scale to mean 0 and std 1 toDo: Maybe min_max_scaler?\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation toDo: is this necessary?\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"lin_reg.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    joblib.dump(model_predictions, filename=\"lin_reg_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"lin_reg_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"lin_reg_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:28.076527900Z",
     "start_time": "2023-12-26T13:06:28.070513800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "lin_reg(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:41.116737700Z",
     "start_time": "2023-12-26T13:06:28.879599400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  12.22  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.34 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.4]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES: 48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "            name  value\n",
      "42  HomeOwn_Rent  -0.00\n",
      "17     UrineVol1   0.00\n",
      "11        BPSys1   0.00\n",
      "0             NR  -0.00\n",
      "8          Pulse  -0.01\n",
      "12        BPDia1   0.01 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "                    name         value\n",
      "39  HHIncome_75000-99999 -7.485871e+08\n",
      "40   HHIncome_more 99999 -8.586734e+08\n",
      "9               BPSysAve -1.259208e+09\n",
      "14                BPDia2 -1.098259e+10\n",
      "16                BPDia3 -1.140055e+10\n",
      "10              BPDiaAve  2.177340e+10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"lin_reg.pkl\")\n",
    "model_1_predictions = joblib.load(\"lin_reg_predictions.pkl\")\n",
    "model_1_scores = joblib.load(\"lin_reg_scores.pkl\")\n",
    "model_1_time = joblib.load(\"lin_reg_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_1_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_1_predictions)))\n",
    "\n",
    "scores[\"model_1\"] = [np.sqrt(-model_1_scores).mean(), model_1]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_1\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_1_scores))\n",
    "\n",
    "print(\"USED FEATURES:\", model_1[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_1_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_1[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_1[\"regressor\"].coef_.flatten(),\n",
    "        \"abs_value\": np.abs(model_1[\"regressor\"].coef_).flatten()\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:50.506166400Z",
     "start_time": "2023-12-26T13:06:50.481624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def decicion_tree_reg(x, y):\n",
    "    \"\"\"define model 3\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", DecisionTreeRegressor(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__max_depth\": [8],\n",
    "            \"regressor__min_samples_leaf\": [0.0009],  # [0.0008, 0.0009, 0.001],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, scoring=\"neg_root_mean_squared_error\", n_jobs=-1) #ToDo: how does gS work?\n",
    "\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"decicion_tree.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"decicion_tree_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"decicion_tree_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"decicion_tree_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"decicion_tree_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:00.260346400Z",
     "start_time": "2023-12-26T13:07:00.236279800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  3.42  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.38 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.4 0.4 0.4]\n",
      "MEAN SCORE: 0.4\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES:  48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                    name  value\n",
      "23      AgeDecade_ 50-59    0.0\n",
      "32  HHIncome_15000-19999    0.0\n",
      "31  HHIncome_10000-14999    0.0\n",
      "28           Race1_Other    0.0\n",
      "27         Race1_Mexican    0.0\n",
      "26        Race1_Hispanic    0.0 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "           name  value\n",
      "6        Height   0.04\n",
      "18   UrineFlow1   0.05\n",
      "19  Gender_male   0.06\n",
      "7           BMI   0.08\n",
      "1           Age   0.10\n",
      "5        Weight   0.31 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__max_depth: 8\n",
      "regressor__min_samples_leaf: 0.0009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decicion_tree_reg(X_train, y_train)\n",
    "model_3 = joblib.load(\"decicion_tree.pkl\")\n",
    "\n",
    "with open(\"decicion_tree_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions = joblib.load(\"decicion_tree_predictions.pkl\")\n",
    "model_3_scores = joblib.load(\"decicion_tree_scores.pkl\")\n",
    "model_3_time = joblib.load(\"decicion_tree_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_3_predictions)))\n",
    "\n",
    "scores[\"model_3\"] = [np.sqrt(-model_3_scores).mean(), model_3]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_3\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_3_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_3[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_3_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_3[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_3[\"regressor\"].feature_importances_,\n",
    "        \"abs_value\": np.abs(model_3[\"regressor\"].feature_importances_)\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:09.003828100Z",
     "start_time": "2023-12-26T13:07:05.541744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "\n",
    "def SVR_class(x, y):\n",
    "    \"\"\"Define model 3\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", SVC()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__kernel\": [\"rbf\"],\n",
    "            \"classifier__degree\": [2],  # [2, 3],\n",
    "            \"classifier__C\": [10],  # [1, 1e-1, 1e-2, 10, 100],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"SVR_class.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model, ff)\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"SVR_class_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"SVR_class_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"SVR_class_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"SVR_class_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:05:12.458783400Z",
     "start_time": "2023-12-23T16:05:12.445775100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 201, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 745, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 207, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[110], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mSVR_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m model_3 \u001B[38;5;241m=\u001B[39m joblib\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSVR_class.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSVR_class_best_params.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "Cell \u001B[1;32mIn[109], line 24\u001B[0m, in \u001B[0;36mSVR_class\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m     13\u001B[0m model_param \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# softmax regression\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     {\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     }\n\u001B[0;32m     21\u001B[0m ]\n\u001B[0;32m     23\u001B[0m model_gs \u001B[38;5;241m=\u001B[39m GridSearchCV(base_model, model_param, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1_weighted\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m \u001B[43mmodel_gs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m model \u001B[38;5;241m=\u001B[39m model_gs\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[0;32m     28\u001B[0m model_best_params \u001B[38;5;241m=\u001B[39m model_gs\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    870\u001B[0m     )\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1387\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1388\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    844\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    846\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    849\u001B[0m     )\n\u001B[1;32m--> 851\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    856\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m     )\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    377\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 201, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 745, in _validate_targets\n    check_classification_targets(y)\n  File \"C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 207, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n"
     ]
    }
   ],
   "source": [
    "SVR_class(X_train, y_train)\n",
    "\n",
    "model_3 = joblib.load(\"SVR_class.pkl\")\n",
    "\n",
    "with open(\"SVR_class_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions = joblib.load(\"SVR_class_predictions.pkl\")\n",
    "model_3_predictions_cv = joblib.load(\"SVR_class_predictions_cv.pkl\")\n",
    "model_3_time = joblib.load(\"SVR_class_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train, model_3_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train, model_3_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train, model_3_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train, model_3_predictions_cv))\n",
    "\n",
    "model_3_score = f1_score(y_train, model_3_predictions_cv, average=\"weighted\")\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_3_score, 2), \"\\n\")\n",
    "scores[\"model_3\"] = [model_3_score, model_3]\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T16:05:32.856264400Z",
     "start_time": "2023-12-23T16:05:32.234617200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def random_f_class(x, y):\n",
    "    \"\"\"Define model 4\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", RandomForestClassifier(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__n_estimators\": [600],  # [10, 50, 100, 200, 400, 600, 800],\n",
    "            \"classifier__max_depth\": [20],  # [None, 5, 10, 20, 30, 50],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"random_f_class.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"random_f_class_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"random_f_class_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"random_f_class_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"random_f_class_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:41.210174500Z",
     "start_time": "2023-12-26T13:07:41.192161100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "        NR  Age  AgeMonths  HHIncomeMid  Poverty  HomeRooms  Weight  Height  \\\n0     9217   44        NaN      30000.0     1.31        8.0    93.3   178.7   \n1     7325   50        NaN          NaN      NaN        7.0   118.0   182.2   \n2      919   59      718.0      50000.0     4.62        7.0    88.1   171.2   \n3     5903   40        NaN       2500.0     0.12        7.0    97.9   167.8   \n4     2808   13      166.0          NaN      NaN        6.0    45.2   151.9   \n...    ...  ...        ...          ...      ...        ...     ...     ...   \n7995  9786   80        NaN      50000.0     3.48        6.0    69.8   149.1   \n7996  7764   27        NaN      22500.0     0.89        7.0    97.0   157.4   \n7997  5219   10        NaN     100000.0     5.00       11.0    34.5   142.3   \n7998  1347   23      281.0          NaN      NaN        NaN    51.6   155.7   \n7999  3583   35      423.0      40000.0     1.85        4.0   117.4   165.5   \n\n        BMI  Pulse  ...  TVHrsDayChild  CompHrsDayChild  AlcoholDay  \\\n0     29.20   62.0  ...            NaN              NaN         1.0   \n1     35.50   72.0  ...            NaN              NaN         1.0   \n2     30.06   60.0  ...            NaN              NaN         2.0   \n3     34.80   92.0  ...            NaN              NaN         NaN   \n4     19.59   64.0  ...            NaN              NaN         NaN   \n...     ...    ...  ...            ...              ...         ...   \n7995  31.40   92.0  ...            NaN              NaN         NaN   \n7996  39.20   70.0  ...            NaN              NaN         1.0   \n7997  17.00   94.0  ...            NaN              NaN         NaN   \n7998  21.28   80.0  ...            NaN              NaN         3.0   \n7999  42.86   86.0  ...            NaN              NaN         NaN   \n\n      AlcoholYear  SmokeAge  AgeFirstMarij  AgeRegMarij  SexAge  \\\n0             1.0      17.0           17.0          NaN    17.0   \n1             3.0       NaN            NaN          NaN    24.0   \n2             2.0       NaN            NaN          NaN    17.0   \n3             NaN       NaN            NaN          NaN     NaN   \n4             NaN       NaN            NaN          NaN     NaN   \n...           ...       ...            ...          ...     ...   \n7995          NaN       NaN            NaN          NaN     NaN   \n7996         12.0      16.0           15.0          NaN    17.0   \n7997          NaN       NaN            NaN          NaN     NaN   \n7998         72.0      16.0           16.0          NaN    14.0   \n7999          NaN       NaN            NaN          NaN    13.0   \n\n      SexNumPartnLife  SexNumPartYear  \n0                20.0             1.0  \n1                 1.0             0.0  \n2                 3.0             1.0  \n3                 NaN             NaN  \n4                 NaN             NaN  \n...               ...             ...  \n7995              NaN             NaN  \n7996              3.0             1.0  \n7997              NaN             NaN  \n7998             15.0             3.0  \n7999              5.0             1.0  \n\n[8000 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NR</th>\n      <th>Age</th>\n      <th>AgeMonths</th>\n      <th>HHIncomeMid</th>\n      <th>Poverty</th>\n      <th>HomeRooms</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>BMI</th>\n      <th>Pulse</th>\n      <th>...</th>\n      <th>TVHrsDayChild</th>\n      <th>CompHrsDayChild</th>\n      <th>AlcoholDay</th>\n      <th>AlcoholYear</th>\n      <th>SmokeAge</th>\n      <th>AgeFirstMarij</th>\n      <th>AgeRegMarij</th>\n      <th>SexAge</th>\n      <th>SexNumPartnLife</th>\n      <th>SexNumPartYear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9217</td>\n      <td>44</td>\n      <td>NaN</td>\n      <td>30000.0</td>\n      <td>1.31</td>\n      <td>8.0</td>\n      <td>93.3</td>\n      <td>178.7</td>\n      <td>29.20</td>\n      <td>62.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7325</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>118.0</td>\n      <td>182.2</td>\n      <td>35.50</td>\n      <td>72.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>919</td>\n      <td>59</td>\n      <td>718.0</td>\n      <td>50000.0</td>\n      <td>4.62</td>\n      <td>7.0</td>\n      <td>88.1</td>\n      <td>171.2</td>\n      <td>30.06</td>\n      <td>60.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5903</td>\n      <td>40</td>\n      <td>NaN</td>\n      <td>2500.0</td>\n      <td>0.12</td>\n      <td>7.0</td>\n      <td>97.9</td>\n      <td>167.8</td>\n      <td>34.80</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2808</td>\n      <td>13</td>\n      <td>166.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>45.2</td>\n      <td>151.9</td>\n      <td>19.59</td>\n      <td>64.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>9786</td>\n      <td>80</td>\n      <td>NaN</td>\n      <td>50000.0</td>\n      <td>3.48</td>\n      <td>6.0</td>\n      <td>69.8</td>\n      <td>149.1</td>\n      <td>31.40</td>\n      <td>92.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>7764</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>22500.0</td>\n      <td>0.89</td>\n      <td>7.0</td>\n      <td>97.0</td>\n      <td>157.4</td>\n      <td>39.20</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>12.0</td>\n      <td>16.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>5219</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>100000.0</td>\n      <td>5.00</td>\n      <td>11.0</td>\n      <td>34.5</td>\n      <td>142.3</td>\n      <td>17.00</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>1347</td>\n      <td>23</td>\n      <td>281.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>51.6</td>\n      <td>155.7</td>\n      <td>21.28</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>72.0</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>15.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>3583</td>\n      <td>35</td>\n      <td>423.0</td>\n      <td>40000.0</td>\n      <td>1.85</td>\n      <td>4.0</td>\n      <td>117.4</td>\n      <td>165.5</td>\n      <td>42.86</td>\n      <td>86.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:12:45.049839300Z",
     "start_time": "2023-12-26T13:12:45.012435600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5142 entries, 0 to 7997\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           5142 non-null   int64  \n",
      " 1   Age          5142 non-null   int64  \n",
      " 2   HHIncomeMid  5142 non-null   float64\n",
      " 3   Poverty      5142 non-null   float64\n",
      " 4   HomeRooms    5142 non-null   float64\n",
      " 5   Weight       5142 non-null   float64\n",
      " 6   Height       5142 non-null   float64\n",
      " 7   BMI          5142 non-null   float64\n",
      " 8   Pulse        5142 non-null   float64\n",
      " 9   BPSysAve     5142 non-null   float64\n",
      " 10  BPDiaAve     5142 non-null   float64\n",
      " 11  BPSys1       5142 non-null   float64\n",
      " 12  BPDia1       5142 non-null   float64\n",
      " 13  BPSys2       5142 non-null   float64\n",
      " 14  BPDia2       5142 non-null   float64\n",
      " 15  BPSys3       5142 non-null   float64\n",
      " 16  BPDia3       5142 non-null   float64\n",
      " 17  DirectChol   5142 non-null   float64\n",
      " 18  UrineVol1    5142 non-null   float64\n",
      " 19  UrineFlow1   5142 non-null   float64\n",
      " 20  Diabetes     5142 non-null   float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 883.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_29744\\3961034604.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('project_1_train.csv')\n",
    "#Applying the condition, but leave nan for now\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'Yes', 0, inplace=True)\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'No', 1, inplace=True)\n",
    "df[\"Diabetes\"] = df[\"Diabetes\"].astype(float)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df = df.select_dtypes(include=numerics)\n",
    "\n",
    "\n",
    "\n",
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:32.048348200Z",
     "start_time": "2023-12-26T13:36:31.964470100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "y_clas = newdf['Diabetes']\n",
    "\n",
    "x_clas = newdf.drop(columns=['Diabetes'])\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(x_clas, y_clas, test_size=0.2, random_state=123)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:46.318029200Z",
     "start_time": "2023-12-26T13:36:46.295413400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "        NR  Age  HHIncomeMid  Poverty  HomeRooms  Weight  Height    BMI  \\\n5211  3897   50      87500.0     3.63       10.0   108.9   180.5  33.43   \n1475   291   65     100000.0     5.00        7.0    67.8   175.5  22.01   \n6290  5526   24      50000.0     2.33        4.0    92.6   176.4  29.80   \n7967  2429   64     100000.0     5.00       10.0    98.0   176.0  31.64   \n3271  9723   57      70000.0     3.13        5.0    70.8   169.3  24.70   \n...    ...  ...          ...      ...        ...     ...     ...    ...   \n2412   407   22      60000.0     1.39        5.0    63.8   162.0  24.31   \n6275  8296   73      87500.0     2.20        5.0    82.9   169.9  28.70   \n2020  5615   50      87500.0     5.00        7.0    94.2   175.5  30.60   \n5340  6515   22      30000.0     1.67        5.0    76.1   154.9  31.70   \n5530  2117   38     100000.0     4.99        4.0    66.8   163.9  24.87   \n\n      Pulse  BPSysAve  BPDiaAve  BPSys1  BPDia1  BPSys2  BPDia2  BPSys3  \\\n5211   76.0     125.0      72.0   124.0    70.0   128.0    72.0   122.0   \n1475   82.0     114.0      53.0   112.0    54.0   114.0    52.0   114.0   \n6290   70.0     102.0      56.0   102.0    58.0   102.0    56.0   102.0   \n7967   66.0     116.0      67.0   114.0    64.0   116.0    66.0   116.0   \n3271   48.0     113.0      65.0   114.0    66.0   116.0    66.0   110.0   \n...     ...       ...       ...     ...     ...     ...     ...     ...   \n2412   62.0     119.0      49.0   118.0    46.0   120.0    46.0   118.0   \n6275   78.0     123.0      65.0   124.0    62.0   126.0    62.0   120.0   \n2020   78.0     110.0      79.0   112.0    84.0   108.0    80.0   112.0   \n5340   70.0     119.0      51.0   116.0    50.0   120.0    48.0   118.0   \n5530   64.0     107.0      70.0   102.0    70.0   106.0    70.0   108.0   \n\n      BPDia3  DirectChol  UrineVol1  UrineFlow1  \n5211    72.0        1.06       64.0       0.753  \n1475    54.0        1.60       21.0       0.368  \n6290    56.0        1.06       33.0       0.068  \n7967    68.0        0.93       67.0       0.677  \n3271    64.0        1.14       97.0       0.890  \n...      ...         ...        ...         ...  \n2412    52.0        2.12      242.0       1.485  \n6275    68.0        1.06       23.0       0.299  \n2020    78.0        0.85       56.0       0.339  \n5340    54.0        1.34       54.0       0.551  \n5530    70.0        1.53      212.0       0.951  \n\n[4113 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NR</th>\n      <th>Age</th>\n      <th>HHIncomeMid</th>\n      <th>Poverty</th>\n      <th>HomeRooms</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>BMI</th>\n      <th>Pulse</th>\n      <th>BPSysAve</th>\n      <th>BPDiaAve</th>\n      <th>BPSys1</th>\n      <th>BPDia1</th>\n      <th>BPSys2</th>\n      <th>BPDia2</th>\n      <th>BPSys3</th>\n      <th>BPDia3</th>\n      <th>DirectChol</th>\n      <th>UrineVol1</th>\n      <th>UrineFlow1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5211</th>\n      <td>3897</td>\n      <td>50</td>\n      <td>87500.0</td>\n      <td>3.63</td>\n      <td>10.0</td>\n      <td>108.9</td>\n      <td>180.5</td>\n      <td>33.43</td>\n      <td>76.0</td>\n      <td>125.0</td>\n      <td>72.0</td>\n      <td>124.0</td>\n      <td>70.0</td>\n      <td>128.0</td>\n      <td>72.0</td>\n      <td>122.0</td>\n      <td>72.0</td>\n      <td>1.06</td>\n      <td>64.0</td>\n      <td>0.753</td>\n    </tr>\n    <tr>\n      <th>1475</th>\n      <td>291</td>\n      <td>65</td>\n      <td>100000.0</td>\n      <td>5.00</td>\n      <td>7.0</td>\n      <td>67.8</td>\n      <td>175.5</td>\n      <td>22.01</td>\n      <td>82.0</td>\n      <td>114.0</td>\n      <td>53.0</td>\n      <td>112.0</td>\n      <td>54.0</td>\n      <td>114.0</td>\n      <td>52.0</td>\n      <td>114.0</td>\n      <td>54.0</td>\n      <td>1.60</td>\n      <td>21.0</td>\n      <td>0.368</td>\n    </tr>\n    <tr>\n      <th>6290</th>\n      <td>5526</td>\n      <td>24</td>\n      <td>50000.0</td>\n      <td>2.33</td>\n      <td>4.0</td>\n      <td>92.6</td>\n      <td>176.4</td>\n      <td>29.80</td>\n      <td>70.0</td>\n      <td>102.0</td>\n      <td>56.0</td>\n      <td>102.0</td>\n      <td>58.0</td>\n      <td>102.0</td>\n      <td>56.0</td>\n      <td>102.0</td>\n      <td>56.0</td>\n      <td>1.06</td>\n      <td>33.0</td>\n      <td>0.068</td>\n    </tr>\n    <tr>\n      <th>7967</th>\n      <td>2429</td>\n      <td>64</td>\n      <td>100000.0</td>\n      <td>5.00</td>\n      <td>10.0</td>\n      <td>98.0</td>\n      <td>176.0</td>\n      <td>31.64</td>\n      <td>66.0</td>\n      <td>116.0</td>\n      <td>67.0</td>\n      <td>114.0</td>\n      <td>64.0</td>\n      <td>116.0</td>\n      <td>66.0</td>\n      <td>116.0</td>\n      <td>68.0</td>\n      <td>0.93</td>\n      <td>67.0</td>\n      <td>0.677</td>\n    </tr>\n    <tr>\n      <th>3271</th>\n      <td>9723</td>\n      <td>57</td>\n      <td>70000.0</td>\n      <td>3.13</td>\n      <td>5.0</td>\n      <td>70.8</td>\n      <td>169.3</td>\n      <td>24.70</td>\n      <td>48.0</td>\n      <td>113.0</td>\n      <td>65.0</td>\n      <td>114.0</td>\n      <td>66.0</td>\n      <td>116.0</td>\n      <td>66.0</td>\n      <td>110.0</td>\n      <td>64.0</td>\n      <td>1.14</td>\n      <td>97.0</td>\n      <td>0.890</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>407</td>\n      <td>22</td>\n      <td>60000.0</td>\n      <td>1.39</td>\n      <td>5.0</td>\n      <td>63.8</td>\n      <td>162.0</td>\n      <td>24.31</td>\n      <td>62.0</td>\n      <td>119.0</td>\n      <td>49.0</td>\n      <td>118.0</td>\n      <td>46.0</td>\n      <td>120.0</td>\n      <td>46.0</td>\n      <td>118.0</td>\n      <td>52.0</td>\n      <td>2.12</td>\n      <td>242.0</td>\n      <td>1.485</td>\n    </tr>\n    <tr>\n      <th>6275</th>\n      <td>8296</td>\n      <td>73</td>\n      <td>87500.0</td>\n      <td>2.20</td>\n      <td>5.0</td>\n      <td>82.9</td>\n      <td>169.9</td>\n      <td>28.70</td>\n      <td>78.0</td>\n      <td>123.0</td>\n      <td>65.0</td>\n      <td>124.0</td>\n      <td>62.0</td>\n      <td>126.0</td>\n      <td>62.0</td>\n      <td>120.0</td>\n      <td>68.0</td>\n      <td>1.06</td>\n      <td>23.0</td>\n      <td>0.299</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>5615</td>\n      <td>50</td>\n      <td>87500.0</td>\n      <td>5.00</td>\n      <td>7.0</td>\n      <td>94.2</td>\n      <td>175.5</td>\n      <td>30.60</td>\n      <td>78.0</td>\n      <td>110.0</td>\n      <td>79.0</td>\n      <td>112.0</td>\n      <td>84.0</td>\n      <td>108.0</td>\n      <td>80.0</td>\n      <td>112.0</td>\n      <td>78.0</td>\n      <td>0.85</td>\n      <td>56.0</td>\n      <td>0.339</td>\n    </tr>\n    <tr>\n      <th>5340</th>\n      <td>6515</td>\n      <td>22</td>\n      <td>30000.0</td>\n      <td>1.67</td>\n      <td>5.0</td>\n      <td>76.1</td>\n      <td>154.9</td>\n      <td>31.70</td>\n      <td>70.0</td>\n      <td>119.0</td>\n      <td>51.0</td>\n      <td>116.0</td>\n      <td>50.0</td>\n      <td>120.0</td>\n      <td>48.0</td>\n      <td>118.0</td>\n      <td>54.0</td>\n      <td>1.34</td>\n      <td>54.0</td>\n      <td>0.551</td>\n    </tr>\n    <tr>\n      <th>5530</th>\n      <td>2117</td>\n      <td>38</td>\n      <td>100000.0</td>\n      <td>4.99</td>\n      <td>4.0</td>\n      <td>66.8</td>\n      <td>163.9</td>\n      <td>24.87</td>\n      <td>64.0</td>\n      <td>107.0</td>\n      <td>70.0</td>\n      <td>102.0</td>\n      <td>70.0</td>\n      <td>106.0</td>\n      <td>70.0</td>\n      <td>108.0</td>\n      <td>70.0</td>\n      <td>1.53</td>\n      <td>212.0</td>\n      <td>0.951</td>\n    </tr>\n  </tbody>\n</table>\n<p>4113 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:54.833372500Z",
     "start_time": "2023-12-26T13:36:54.797810700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "random_f_class(X_train_c, y_train_c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:37:18.665601800Z",
     "start_time": "2023-12-26T13:36:57.260670600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  21.17  sec\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "[[ 348    0]\n",
      " [   0 3765]] \n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[ 103  245]\n",
      " [  11 3754]] \n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       348\n",
      "         1.0       1.00      1.00      1.00      3765\n",
      "\n",
      "    accuracy                           1.00      4113\n",
      "   macro avg       1.00      1.00      1.00      4113\n",
      "weighted avg       1.00      1.00      1.00      4113\n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.30      0.45       348\n",
      "         1.0       0.94      1.00      0.97      3765\n",
      "\n",
      "    accuracy                           0.94      4113\n",
      "   macro avg       0.92      0.65      0.71      4113\n",
      "weighted avg       0.94      0.94      0.92      4113\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.92 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__max_depth: 20\n",
      "classifier__n_estimators: 600\n",
      "pca__n_components: 0.9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "model_4 = joblib.load(\"random_f_class.pkl\")\n",
    "\n",
    "with open(\"random_f_class_best_params.pkl\", 'rb') as f:\n",
    "    model_4_best_params = pickle.load(f)\n",
    "\n",
    "model_4_predictions = joblib.load(\"random_f_class_predictions.pkl\")\n",
    "model_4_predictions_cv = joblib.load(\"random_f_class_predictions_cv.pkl\")\n",
    "model_4_time = joblib.load(\"random_f_class_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_4_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_4_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_4_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_4_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_4_predictions_cv))\n",
    "\n",
    "model_4_score = f1_score(y_train_c, model_4_predictions_cv, average=\"weighted\")\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_4_score, 2), \"\\n\")\n",
    "scores[\"model_4\"] = [model_4_score, model_4]\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_4_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:41:33.642213700Z",
     "start_time": "2023-12-26T13:41:33.382322500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def run_model_2(x, y):\n",
    "    \"\"\"Define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # binary fit for each label\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__multi_class\": [\"ovr\"],  # binary fit for each label\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"lbfgs\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        },\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__multi_class\": [\"multinomial\"],  # softmax regression\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"saga\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"log_reg_cl.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"log_reg_cl_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"log_reg_cl_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"log_reg_cl_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"log_reg_cl_time.pkl\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:51:56.241592400Z",
     "start_time": "2023-12-26T13:51:56.196566300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  0.17  sec\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "[[   0  348]\n",
      " [   0 3765]] \n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[   0  348]\n",
      " [   0 3765]] \n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       348\n",
      "         1.0       0.92      1.00      0.96      3765\n",
      "\n",
      "    accuracy                           0.92      4113\n",
      "   macro avg       0.46      0.50      0.48      4113\n",
      "weighted avg       0.84      0.92      0.87      4113\n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       348\n",
      "         1.0       0.92      1.00      0.96      3765\n",
      "\n",
      "    accuracy                           0.92      4113\n",
      "   macro avg       0.46      0.50      0.48      4113\n",
      "weighted avg       0.84      0.92      0.87      4113\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.87 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 0.1\n",
      "classifier__multi_class: ovr\n",
      "classifier__penalty: l2\n",
      "classifier__solver: lbfgs\n",
      "pca__n_components: 0.9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_model_2(X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "model_2 = joblib.load(\"log_reg_cl.pkl\")\n",
    "\n",
    "with open(\"log_reg_cl_best_params.pkl\", 'rb') as f:\n",
    "    model_2_best_params = pickle.load(f)\n",
    "\n",
    "model_2_predictions = joblib.load(\"log_reg_cl_predictions.pkl\")\n",
    "model_2_predictions_cv = joblib.load(\"log_reg_cl_predictions_cv.pkl\")\n",
    "model_2_time = joblib.load(\"log_reg_cl_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_2_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_2_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_2_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_2_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_2_predictions_cv))\n",
    "\n",
    "model_2_score = f1_score(y_train_c, model_2_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_2\"] = [model_2_score, model_2]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_2_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_2_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T13:53:20.362279800Z",
     "start_time": "2023-12-26T13:53:20.156575300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
