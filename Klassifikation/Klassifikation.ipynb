{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:12:37.695462300Z",
     "start_time": "2024-01-27T14:12:15.596846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n        <style>\n            .support_message_main_box {\n                position: relative;\n                display: table-cell;\n                vertical-align: middle;\n                width: 100%;\n                height: 8em;\n                padding: 1em;\n                padding-left: 11em;\n                background-color: #f7f7f7;\n                border: 1px solid #cfcfcf;\n                border-radius: 2px;\n            }\n            .support_message_main_box img {\n                position: absolute;\n                height: 9em;\n                width: 9em;\n                left: 0.5em;\n                top: 0.5em;\n                border-radius: 1em;\n            }\n        </style>\n        <div class=\"support_message_main_box\">\n            <img src=\"https://avatars.githubusercontent.com/u/7738570?v=4\" />\n            <p>\n            <b>Hi!</b><br/>\n            <span>I am the author of\n            <a href=\"https://github.com/LucaCappelletti94/silence_tensorflow\" target=\"_blank\">\n                silence_tensorflow\n            </a>, which you use in this Notebook.\n            </span><br/>\n            \n            <span>I love to code, but I also need coffee.</span>\n            <a href=\"https://github.com/sponsors/LucaCappelletti94\" target=\"_blank\">\n                Please sponsor me on GitHub ‚ù§Ô∏è\n            </a><br/>\n            <i>Good luck in your coding üçÄ!</i>\n            <br/>\n            <i>- Luca</i>\n            </p>\n        <div>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   23  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.406  0.407  0.408  \\\n0   7  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n1  16  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n2  15  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n3  23  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n4  17  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n\n   0.409  0.410  0.411  0.412  0.413  0.414  0.415  \n0      0      0      0      0      0      0      0  \n1      0      0      0      0      0      0      0  \n2      0      0      0      0      0      0      0  \n3      0      0      0      0      0      0      0  \n4      0      0      0      0      0      0      0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>23</th>\n      <th>0</th>\n      <th>0.1</th>\n      <th>0.2</th>\n      <th>0.3</th>\n      <th>0.4</th>\n      <th>0.5</th>\n      <th>0.6</th>\n      <th>0.7</th>\n      <th>0.8</th>\n      <th>...</th>\n      <th>0.406</th>\n      <th>0.407</th>\n      <th>0.408</th>\n      <th>0.409</th>\n      <th>0.410</th>\n      <th>0.411</th>\n      <th>0.412</th>\n      <th>0.413</th>\n      <th>0.414</th>\n      <th>0.415</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 785 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin, TransformerMixin\n",
    "\n",
    "# to avoid (hopefully unimportant) warnings\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "from absl import logging\n",
    "\n",
    "silence_tensorflow()\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "\n",
    "class MyDynamicKerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom regressor that wraps a dynamic Keras model for use with scikit-learn pipelines.\n",
    "    This wrapper is necessary because sometimes (e.g. when using pca in pipeline) the input shape is not clear apriori\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, epochs=None, batch_size=None, verbose=0, optimizer=\"adam\", loss=None, metrics=None):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.keras_model = None\n",
    "        self.history = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            self.keras_model = self.model(input_shape=(x.shape[1],))\n",
    "            self.keras_model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "            self.history = self.keras_model.fit(x, y, epochs=self.epochs, batch_size=self.batch_size,\n",
    "                                                verbose=self.verbose)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict using the Keras model.\"\"\"\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            raise Exception(\"The model has not been fitted yet!\")\n",
    "        else:\n",
    "            predictions = self.keras_model.predict(x, verbose=self.verbose)\n",
    "            return np.ravel(predictions)\n",
    "\n",
    "    def score(self, x, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Returns the mean squared error on the given test data and labels.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(x)\n",
    "        mse = np.mean((predictions - y) ** 2)\n",
    "        return -mse  # Negative MSE because scikit-learn's convention is that higher return values are better\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get parameters for this estimator.\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"verbose\": self.verbose,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"loss\": self.loss,\n",
    "            \"metrics\": self.metrics,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set parameters for this estimator.\"\"\"\n",
    "        valid_params = self.get_params(deep=True)\n",
    "        for parameter, value in params.items():\n",
    "            if parameter in valid_params:\n",
    "                setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "class MyDynamicKerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Custom classifier that wraps a dynamic Keras model for use with scikit-learn pipelines.\n",
    "    This wrapper is necessary because sometimes (e.g. when using pca in pipeline) the input shape is not clear apriori\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, epochs=None, batch_size=None, verbose=0, optimizer=\"adam\", loss=None, metrics=None,\n",
    "                 cnn=False, cnn_shape_list=None):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "        self.cnn = cnn\n",
    "        self.cnn_shape_list = cnn_shape_list\n",
    "        self.keras_model = None\n",
    "        self.history = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        # convert y to numpy array and set classes_\n",
    "        y = np.array(y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            if self.cnn:\n",
    "                x_new = x.reshape(self.cnn_shape_list)\n",
    "                self.keras_model = self.model(input_shape=x_new.shape[1:])\n",
    "                self.keras_model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "                self.history = self.keras_model.fit(x_new, y, epochs=self.epochs, batch_size=self.batch_size,\n",
    "                                                    verbose=self.verbose)\n",
    "            else:\n",
    "                self.keras_model = self.model(input_shape=(x.shape[1],))\n",
    "                self.keras_model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "                self.history = self.keras_model.fit(x, y, epochs=self.epochs, batch_size=self.batch_size,\n",
    "                                                    verbose=self.verbose)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict using the Keras model.\"\"\"\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            raise Exception(\"The model has not been fitted yet!\")\n",
    "        elif self.cnn:\n",
    "            x_new = x.reshape(self.cnn_shape_list)\n",
    "            probabilities = self.keras_model.predict(x_new, verbose=self.verbose)\n",
    "        else:\n",
    "            probabilities = self.keras_model.predict(x, verbose=self.verbose)\n",
    "\n",
    "        if probabilities.shape[1] == 1:\n",
    "            # Use 0.5 as the threshold to convert probabilities to binary labels\n",
    "            return (probabilities > 0.5).astype('int32')\n",
    "        else:\n",
    "            # Use argmax for multi-class problems\n",
    "            return probabilities.argmax(axis=1)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get parameters for this estimator.\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"verbose\": self.verbose,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"loss\": self.loss,\n",
    "            \"metrics\": self.metrics,\n",
    "            \"cnn\": self.cnn,\n",
    "            \"cnn_shape_list\": self.cnn_shape_list,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set parameters for this estimator.\"\"\"\n",
    "        valid_params = self.get_params(deep=True)\n",
    "        for parameter, value in params.items():\n",
    "            if parameter in valid_params:\n",
    "                setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selcects the features (numerical, categorical or all)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, select):\n",
    "        \"\"\"\n",
    "        select has to be \"num features\", \"cat features\" or \"all features\"\n",
    "        \"\"\"\n",
    "\n",
    "        if select not in [\"num features\", \"cat features\", \"all features\"]:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        self.select = select\n",
    "        self.num_attr = None\n",
    "        self.cat_attr = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        self.num_attr = list(x.select_dtypes(include=[np.number]).columns)\n",
    "        self.cat_attr = list(x.select_dtypes(exclude=[np.number]).columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"does the transformation\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        if self.select == \"num features\":\n",
    "            x_new = x[self.num_attr].copy()\n",
    "        elif self.select == \"cat features\":\n",
    "            x_new = x[self.cat_attr].copy()\n",
    "        elif self.select == \"all features\":\n",
    "            x_new = x[self.num_attr + self.cat_attr].copy()\n",
    "        else:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"this method is needed, otherwise we cannot use set_ouput\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'./../projekt2_train.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Labels und Features trennen\n",
    "X = data.drop(columns=data.columns[0]).values\n",
    "y = data[data.columns[0]].values\n",
    "\n",
    "# Normalisierung der Features\n",
    "X = X / 255.0\n",
    "\n",
    "# Umwandeln der Labels in kategorische Daten\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Aufteilung in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:12:52.952064200Z",
     "start_time": "2024-01-27T14:12:50.548784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 11m 34s]\n",
      "val_accuracy: 0.9040728211402893\n",
      "\n",
      "Best val_accuracy So Far: 0.9063438375790914\n",
      "Total elapsed time: 00h 43m 30s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                    activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(hp.Float('dropout_' + str(i), min_value=0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='dnn_classification'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "# Beste Modellkonfiguration abrufen\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T15:10:08.231081700Z",
     "start_time": "2024-01-27T15:10:08.021196400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 384)               301440    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                36960     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                3104      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 27)                891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 342,395\n",
      "Trainable params: 342,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T15:13:04.173000700Z",
     "start_time": "2024-01-27T15:13:04.147963600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_52876\\4080674537.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 2.2615 - accuracy: 0.3250\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 20s 4ms/step - loss: 1.6207 - accuracy: 0.5009\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 17s 4ms/step - loss: 1.4525 - accuracy: 0.5529\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 17s 4ms/step - loss: 1.3651 - accuracy: 0.5820\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 17s 4ms/step - loss: 1.2998 - accuracy: 0.6060\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.2456 - accuracy: 0.6249\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.2319 - accuracy: 0.6312\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 20s 4ms/step - loss: 1.1998 - accuracy: 0.6429\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.1704 - accuracy: 0.6527\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.1618 - accuracy: 0.6550\n",
      "740/740 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 21s 4ms/step - loss: 2.2313 - accuracy: 0.3335\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.5921 - accuracy: 0.5124\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.4250 - accuracy: 0.5643\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 22s 5ms/step - loss: 1.3322 - accuracy: 0.5987\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 22s 5ms/step - loss: 1.2736 - accuracy: 0.6138\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 20s 4ms/step - loss: 1.2293 - accuracy: 0.6295\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.2018 - accuracy: 0.6370\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.1701 - accuracy: 0.6513\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.1538 - accuracy: 0.6518\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 23s 5ms/step - loss: 1.1307 - accuracy: 0.6606\n",
      "740/740 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 2.1998 - accuracy: 0.3335\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 1.6016 - accuracy: 0.5059\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 1.4359 - accuracy: 0.5620\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 20s 4ms/step - loss: 1.3376 - accuracy: 0.5931\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 21s 4ms/step - loss: 1.2809 - accuracy: 0.6125\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 19s 4ms/step - loss: 1.2395 - accuracy: 0.6225\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 1.2143 - accuracy: 0.6382\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 1.1903 - accuracy: 0.6442\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 18s 4ms/step - loss: 1.1717 - accuracy: 0.6518\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 20s 4ms/step - loss: 1.1516 - accuracy: 0.6567\n",
      "740/740 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Funktion, die das Keras-Modell erstellt\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(384, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(96, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(27, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Erstellen des KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Cross-validation Vorhersagen\n",
    "predictions = cross_val_predict(model, X_train, y_train, cv=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:13:15.806032400Z",
     "start_time": "2024-01-28T11:03:33.732619300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.8106955334393784\n",
      "Precision: 0.815390010620604\n",
      "Recall: 0.8099783830230405\n",
      "F1-Score: 0.8086725745140663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Konvertieren der One-Hot-codierten Vorhersagen in Klassenindizes, falls erforderlich\n",
    "if predictions.ndim > 1:\n",
    "    predictions_labels = np.argmax(predictions, axis=1)\n",
    "else:\n",
    "    predictions_labels = predictions\n",
    "\n",
    "# Konvertieren der One-Hot-codierten tats√§chlichen Labels in Klassenindizes\n",
    "y_true_labels = np.argmax(y_train, axis=1) if y_train.ndim > 1 else y_train\n",
    "\n",
    "# Berechnung verschiedener Metriken\n",
    "accuracy = accuracy_score(y_true_labels, predictions_labels)\n",
    "precision = precision_score(y_true_labels, predictions_labels, average='macro')\n",
    "recall = recall_score(y_true_labels, predictions_labels, average='macro')\n",
    "f1 = f1_score(y_true_labels, predictions_labels, average='macro')\n",
    "\n",
    "print(\"Genauigkeit:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:13:39.071436600Z",
     "start_time": "2024-01-28T11:13:38.985452400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Speichern des optimierten Keras-Modells\n",
    "best_model.save(\"DNN_optimized_model.h5\")\n",
    "\n",
    "# Speichern der Kreuzvalidierungs-Vorhersagen\n",
    "joblib.dump(predictions, \"DNN_cross_val_predictions.pkl\")\n",
    "\n",
    "# Speichern der besten Hyperparameter des Keras-Tuners\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "with open(\"DNN_best_hyperparameters.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_hyperparameters, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:13:43.559360300Z",
     "start_time": "2024-01-28T11:13:43.526716300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_52876\\4011630861.py:22: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 34s 7ms/step - loss: 1.1092 - accuracy: 0.6638\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 34s 7ms/step - loss: 0.6908 - accuracy: 0.7823\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.5913 - accuracy: 0.8117\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.5267 - accuracy: 0.8317\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.4818 - accuracy: 0.8447\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.4524 - accuracy: 0.8512\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.4295 - accuracy: 0.8585\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.3994 - accuracy: 0.8680\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 38s 8ms/step - loss: 0.3887 - accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 38s 8ms/step - loss: 0.3856 - accuracy: 0.8723\n",
      "740/740 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 1.0774 - accuracy: 0.6693\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.6612 - accuracy: 0.7919\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.5633 - accuracy: 0.8213\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.5087 - accuracy: 0.8366\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.4636 - accuracy: 0.8492\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.4434 - accuracy: 0.8551\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.4140 - accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.3965 - accuracy: 0.8711\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.3854 - accuracy: 0.8729\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 37s 8ms/step - loss: 0.3662 - accuracy: 0.8782\n",
      "740/740 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "4736/4736 [==============================] - 35s 7ms/step - loss: 1.0813 - accuracy: 0.6728\n",
      "Epoch 2/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.6726 - accuracy: 0.7871\n",
      "Epoch 3/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.5670 - accuracy: 0.8203\n",
      "Epoch 4/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.5111 - accuracy: 0.8351\n",
      "Epoch 5/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.4640 - accuracy: 0.8493\n",
      "Epoch 6/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.4343 - accuracy: 0.8569\n",
      "Epoch 7/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.4124 - accuracy: 0.8658\n",
      "Epoch 8/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.3923 - accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.3661 - accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "4736/4736 [==============================] - 36s 8ms/step - loss: 0.3563 - accuracy: 0.8813\n",
      "740/740 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "# CNN-Modell erstellen\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(27, activation='softmax')  # 27 Klassen\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# KerasClassifier Wrapper\n",
    "cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# Umwandlung der Eingabedaten in das ben√∂tigte Format f√ºr CNNs\n",
    "X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Cross-validation Vorhersagen\n",
    "predictions = cross_val_predict(cnn_model, X_train_cnn, y_train, cv=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T19:15:19.756111900Z",
     "start_time": "2024-01-27T18:56:59.862533800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([23, 24,  1, ...,  7,  4, 13])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T10:43:46.856670600Z",
     "start_time": "2024-01-28T10:43:46.828671300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.9056293022142766\n",
      "Precision: 0.9062898676562765\n",
      "Recall: 0.9052862564150287\n",
      "F1-Score: 0.9052812653893703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Wenn y_train One-Hot-encoded ist, konvertieren Sie es zur√ºck in Label-Indizes\n",
    "if y_train.ndim > 1:\n",
    "    y_true_labels = np.argmax(y_train, axis=1)\n",
    "else:\n",
    "    y_true_labels = y_train\n",
    "\n",
    "# Berechnung verschiedener Metriken\n",
    "accuracy = accuracy_score(y_true_labels, predictions)\n",
    "precision = precision_score(y_true_labels, predictions, average='macro')\n",
    "recall = recall_score(y_true_labels, predictions, average='macro')\n",
    "f1 = f1_score(y_true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Genauigkeit:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T10:48:24.713708800Z",
     "start_time": "2024-01-28T10:48:24.609961100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7104/7104 [==============================] - 52s 7ms/step - loss: 0.9804 - accuracy: 0.6982\n",
      "Epoch 2/10\n",
      "7104/7104 [==============================] - 53s 7ms/step - loss: 0.6316 - accuracy: 0.7986\n",
      "Epoch 3/10\n",
      "7104/7104 [==============================] - 57s 8ms/step - loss: 0.5359 - accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "7104/7104 [==============================] - 56s 8ms/step - loss: 0.4889 - accuracy: 0.8437\n",
      "Epoch 5/10\n",
      "7104/7104 [==============================] - 57s 8ms/step - loss: 0.4537 - accuracy: 0.8542\n",
      "Epoch 6/10\n",
      "7104/7104 [==============================] - 57s 8ms/step - loss: 0.4338 - accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.4100 - accuracy: 0.8676\n",
      "Epoch 8/10\n",
      "7104/7104 [==============================] - 55s 8ms/step - loss: 0.3934 - accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "7104/7104 [==============================] - 54s 8ms/step - loss: 0.3830 - accuracy: 0.8725\n",
      "Epoch 10/10\n",
      "7104/7104 [==============================] - 54s 8ms/step - loss: 0.3719 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": "['CNN_cross_val_predictions.pkl']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training des Keras-Modells\n",
    "cnn_model.fit(X_train_cnn, y_train)\n",
    "\n",
    "# Zugriff auf das trainierte Keras-Modell\n",
    "trained_keras_model = cnn_model.model\n",
    "\n",
    "# Speichern des trainierten Keras-Modells\n",
    "trained_keras_model.save(\"CNN_model_trained.h5\")\n",
    "\n",
    "# Kreuzvalidierungs-Vorhersagen waren bereits gemacht\n",
    "# predictions = cross_val_predict(cnn_model, X_train_cnn, y_train, cv=3)\n",
    "\n",
    "# Speichern der Kreuzvalidierungs-Vorhersagen\n",
    "joblib.dump(predictions, \"CNN_cross_val_predictions.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:16.091151Z",
     "start_time": "2024-01-28T10:53:06.338147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:16.091151Z",
     "start_time": "2024-01-28T11:02:16.090237900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:16.091151Z",
     "start_time": "2024-01-28T11:02:16.090237900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:16.091151Z",
     "start_time": "2024-01-28T11:02:16.091151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:16.092148500Z",
     "start_time": "2024-01-28T11:02:16.091151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T11:02:17.243799400Z",
     "start_time": "2024-01-28T11:02:16.092148500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
