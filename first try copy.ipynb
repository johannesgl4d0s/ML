{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.024648500Z",
     "start_time": "2023-12-26T12:59:43.302379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures, PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T12:59:47.026610800Z",
     "start_time": "2023-12-26T12:59:47.025613500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Column Selector based on dtype (from lecture)\n",
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selcects the features (numerical, categorical or all)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, select):\n",
    "        \"\"\"\n",
    "        select has to be \"num features\", \"cat features\" or \"all features\"\n",
    "        \"\"\"\n",
    "\n",
    "        if select not in [\"num features\", \"cat features\", \"all features\"]:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        self.select = select\n",
    "        self.num_attr = None\n",
    "        self.cat_attr = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        self.num_attr = list(x.select_dtypes(include=[np.number]).columns)\n",
    "        self.cat_attr = list(x.select_dtypes(exclude=[np.number]).columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame, _y=None):\n",
    "        \"\"\"does the transformation\"\"\"\n",
    "\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise TypeError(\"Selector needs Pandas Dataframe!\")\n",
    "\n",
    "        if self.select == \"num features\":\n",
    "            x_new = x[self.num_attr].copy()\n",
    "        elif self.select == \"cat features\":\n",
    "            x_new = x[self.cat_attr].copy()\n",
    "        elif self.select == \"all features\":\n",
    "            x_new = x[self.num_attr + self.cat_attr].copy()\n",
    "        else:\n",
    "            raise TypeError(\"for select only num features, cat features or all features\")\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        \"\"\"this method is needed, otherwise we cannot use set_ouput\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:12.705507300Z",
     "start_time": "2023-12-26T13:13:12.639960100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('project_1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:28.341985600Z",
     "start_time": "2023-12-26T13:13:28.313685Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Race1</th>\n",
       "      <th>Race3</th>\n",
       "      <th>Education</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>RegularMarij</th>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <th>HardDrugs</th>\n",
       "      <th>SexEver</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "      <th>SameSex</th>\n",
       "      <th>SexOrientation</th>\n",
       "      <th>PregnantNow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9217</td>\n",
       "      <td>male</td>\n",
       "      <td>44</td>\n",
       "      <td>40-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>High School</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7325</td>\n",
       "      <td>male</td>\n",
       "      <td>50</td>\n",
       "      <td>50-59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>NeverMarried</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Homosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919</td>\n",
       "      <td>female</td>\n",
       "      <td>59</td>\n",
       "      <td>50-59</td>\n",
       "      <td>718.0</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>45000-54999</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5903</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>40-49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>College Grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0-4999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2808</td>\n",
       "      <td>female</td>\n",
       "      <td>13</td>\n",
       "      <td>10-19</td>\n",
       "      <td>166.0</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NR  Gender  Age AgeDecade  AgeMonths     Race1  Race3     Education  \\\n",
       "0  9217    male   44     40-49        NaN     White  White   High School   \n",
       "1  7325    male   50     50-59        NaN     White  White  College Grad   \n",
       "2   919  female   59     50-59      718.0     Black    NaN   High School   \n",
       "3  5903  female   40     40-49        NaN     White  White  College Grad   \n",
       "4  2808  female   13     10-19      166.0  Hispanic    NaN           NaN   \n",
       "\n",
       "  MaritalStatus     HHIncome  ...  RegularMarij  AgeRegMarij  HardDrugs  \\\n",
       "0      Divorced  25000-34999  ...            No          NaN        Yes   \n",
       "1  NeverMarried          NaN  ...            No          NaN         No   \n",
       "2       Widowed  45000-54999  ...            No          NaN         No   \n",
       "3      Divorced       0-4999  ...           NaN          NaN        NaN   \n",
       "4           NaN          NaN  ...           NaN          NaN        NaN   \n",
       "\n",
       "  SexEver SexAge  SexNumPartnLife  SexNumPartYear  SameSex SexOrientation  \\\n",
       "0     Yes   17.0             20.0             1.0       No   Heterosexual   \n",
       "1     Yes   24.0              1.0             0.0      Yes     Homosexual   \n",
       "2     Yes   17.0              3.0             1.0       No   Heterosexual   \n",
       "3     NaN    NaN              NaN             NaN      NaN            NaN   \n",
       "4     NaN    NaN              NaN             NaN      NaN            NaN   \n",
       "\n",
       "  PregnantNow  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3          No  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:29.419496500Z",
     "start_time": "2023-12-26T13:13:29.375926300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 71 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   NR                8000 non-null   int64  \n",
      " 1   Gender            8000 non-null   object \n",
      " 2   Age               8000 non-null   int64  \n",
      " 3   AgeDecade         7740 non-null   object \n",
      " 4   AgeMonths         3975 non-null   float64\n",
      " 5   Race1             8000 non-null   object \n",
      " 6   Race3             3994 non-null   object \n",
      " 7   Education         5800 non-null   object \n",
      " 8   MaritalStatus     5806 non-null   object \n",
      " 9   HHIncome          7359 non-null   object \n",
      " 10  HHIncomeMid       7359 non-null   float64\n",
      " 11  Poverty           7423 non-null   float64\n",
      " 12  HomeRooms         7943 non-null   float64\n",
      " 13  HomeOwn           7948 non-null   object \n",
      " 14  Work              6241 non-null   object \n",
      " 15  Weight            7936 non-null   float64\n",
      " 16  Height            7727 non-null   float64\n",
      " 17  BMI               7716 non-null   float64\n",
      " 18  BMICatUnder20yrs  1016 non-null   object \n",
      " 19  BMI_WHO           7690 non-null   object \n",
      " 20  Pulse             6862 non-null   float64\n",
      " 21  BPSysAve          6851 non-null   float64\n",
      " 22  BPDiaAve          6851 non-null   float64\n",
      " 23  BPSys1            6590 non-null   float64\n",
      " 24  BPDia1            6590 non-null   float64\n",
      " 25  BPSys2            6698 non-null   float64\n",
      " 26  BPDia2            6698 non-null   float64\n",
      " 27  BPSys3            6701 non-null   float64\n",
      " 28  BPDia3            6701 non-null   float64\n",
      " 29  Testosterone      3292 non-null   float64\n",
      " 30  DirectChol        6786 non-null   float64\n",
      " 31  UrineVol1         7211 non-null   float64\n",
      " 32  UrineFlow1        6724 non-null   float64\n",
      " 33  UrineVol2         1181 non-null   float64\n",
      " 34  UrineFlow2        1179 non-null   float64\n",
      " 35  Diabetes          7893 non-null   object \n",
      " 36  HealthGen         6034 non-null   object \n",
      " 37  DaysPhysHlthBad   6028 non-null   float64\n",
      " 38  DaysMentHlthBad   6029 non-null   float64\n",
      " 39  LittleInterest    1240 non-null   object \n",
      " 40  Depressed         1130 non-null   object \n",
      " 41  nPregnancies      2081 non-null   float64\n",
      " 42  nBabies           1934 non-null   float64\n",
      " 43  Age1stBaby        1507 non-null   float64\n",
      " 44  SleepHrsNight     6228 non-null   float64\n",
      " 45  SleepTrouble      6241 non-null   object \n",
      " 46  PhysActive        6687 non-null   object \n",
      " 47  PhysActiveDays    3735 non-null   float64\n",
      " 48  TVHrsDay          3886 non-null   object \n",
      " 49  CompHrsDay        3889 non-null   object \n",
      " 50  TVHrsDayChild     507 non-null    float64\n",
      " 51  CompHrsDayChild   507 non-null    float64\n",
      " 52  Alcohol12PlusYr   5266 non-null   object \n",
      " 53  AlcoholDay        3936 non-null   float64\n",
      " 54  AlcoholYear       4734 non-null   float64\n",
      " 55  SmokeNow          2575 non-null   object \n",
      " 56  Smoke100          5809 non-null   object \n",
      " 57  Smoke100n         5809 non-null   object \n",
      " 58  SmokeAge          2478 non-null   float64\n",
      " 59  Marijuana         3979 non-null   object \n",
      " 60  AgeFirstMarij     2339 non-null   float64\n",
      " 61  RegularMarij      3979 non-null   object \n",
      " 62  AgeRegMarij       1086 non-null   float64\n",
      " 63  HardDrugs         4631 non-null   object \n",
      " 64  SexEver           4633 non-null   object \n",
      " 65  SexAge            4464 non-null   float64\n",
      " 66  SexNumPartnLife   4600 non-null   float64\n",
      " 67  SexNumPartYear    3969 non-null   float64\n",
      " 68  SameSex           4634 non-null   object \n",
      " 69  SexOrientation    3898 non-null   object \n",
      " 70  PregnantNow       1383 non-null   object \n",
      "dtypes: float64(39), int64(2), object(30)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:30.064583600Z",
     "start_time": "2023-12-26T13:13:29.977397400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>...</th>\n",
       "      <th>TVHrsDayChild</th>\n",
       "      <th>CompHrsDayChild</th>\n",
       "      <th>AlcoholDay</th>\n",
       "      <th>AlcoholYear</th>\n",
       "      <th>SmokeAge</th>\n",
       "      <th>AgeFirstMarij</th>\n",
       "      <th>AgeRegMarij</th>\n",
       "      <th>SexAge</th>\n",
       "      <th>SexNumPartnLife</th>\n",
       "      <th>SexNumPartYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>3975.000000</td>\n",
       "      <td>7359.000000</td>\n",
       "      <td>7423.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7936.000000</td>\n",
       "      <td>7727.000000</td>\n",
       "      <td>7716.000000</td>\n",
       "      <td>6862.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>3936.000000</td>\n",
       "      <td>4734.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>2339.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>4464.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>3969.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5012.554250</td>\n",
       "      <td>36.667500</td>\n",
       "      <td>421.240000</td>\n",
       "      <td>57291.411877</td>\n",
       "      <td>2.807810</td>\n",
       "      <td>6.249024</td>\n",
       "      <td>71.160622</td>\n",
       "      <td>161.934088</td>\n",
       "      <td>26.673793</td>\n",
       "      <td>73.484115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950690</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>2.931911</td>\n",
       "      <td>75.257710</td>\n",
       "      <td>17.761905</td>\n",
       "      <td>17.050876</td>\n",
       "      <td>17.753223</td>\n",
       "      <td>17.433468</td>\n",
       "      <td>14.243261</td>\n",
       "      <td>1.356513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2887.242281</td>\n",
       "      <td>22.265459</td>\n",
       "      <td>257.011081</td>\n",
       "      <td>33114.586076</td>\n",
       "      <td>1.684218</td>\n",
       "      <td>2.278170</td>\n",
       "      <td>29.010355</td>\n",
       "      <td>20.154350</td>\n",
       "      <td>7.346642</td>\n",
       "      <td>12.090593</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418238</td>\n",
       "      <td>2.560725</td>\n",
       "      <td>3.187721</td>\n",
       "      <td>102.078749</td>\n",
       "      <td>5.170704</td>\n",
       "      <td>3.944924</td>\n",
       "      <td>4.907613</td>\n",
       "      <td>3.695085</td>\n",
       "      <td>47.260997</td>\n",
       "      <td>2.709867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>83.600000</td>\n",
       "      <td>12.890000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2528.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.300000</td>\n",
       "      <td>157.100000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4994.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>166.100000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7504.250000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>89.200000</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>30.930000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>959.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>230.700000</td>\n",
       "      <td>200.400000</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NR          Age    AgeMonths    HHIncomeMid      Poverty  \\\n",
       "count   8000.000000  8000.000000  3975.000000    7359.000000  7423.000000   \n",
       "mean    5012.554250    36.667500   421.240000   57291.411877     2.807810   \n",
       "std     2887.242281    22.265459   257.011081   33114.586076     1.684218   \n",
       "min        1.000000     0.000000     0.000000    2500.000000     0.000000   \n",
       "25%     2528.750000    18.000000   204.000000   30000.000000     1.240000   \n",
       "50%     4994.000000    36.000000   420.000000   50000.000000     2.720000   \n",
       "75%     7504.250000    54.000000   619.000000   87500.000000     4.760000   \n",
       "max    10000.000000    80.000000   959.000000  100000.000000     5.000000   \n",
       "\n",
       "         HomeRooms       Weight       Height          BMI        Pulse  ...  \\\n",
       "count  7943.000000  7936.000000  7727.000000  7716.000000  6862.000000  ...   \n",
       "mean      6.249024    71.160622   161.934088    26.673793    73.484115  ...   \n",
       "std       2.278170    29.010355    20.154350     7.346642    12.090593  ...   \n",
       "min       1.000000     2.800000    83.600000    12.890000    40.000000  ...   \n",
       "25%       5.000000    56.300000   157.100000    21.600000    64.000000  ...   \n",
       "50%       6.000000    72.750000   166.100000    26.000000    72.000000  ...   \n",
       "75%       8.000000    89.200000   174.500000    30.930000    82.000000  ...   \n",
       "max      13.000000   230.700000   200.400000    81.250000   134.000000  ...   \n",
       "\n",
       "       TVHrsDayChild  CompHrsDayChild   AlcoholDay  AlcoholYear     SmokeAge  \\\n",
       "count     507.000000       507.000000  3936.000000  4734.000000  2478.000000   \n",
       "mean        1.950690         2.230769     2.931911    75.257710    17.761905   \n",
       "std         1.418238         2.560725     3.187721   102.078749     5.170704   \n",
       "min         0.000000         0.000000     1.000000     0.000000     6.000000   \n",
       "25%         1.000000         0.000000     1.000000     3.000000    15.000000   \n",
       "50%         2.000000         1.000000     2.000000    24.000000    17.000000   \n",
       "75%         3.000000         6.000000     3.000000   104.000000    19.000000   \n",
       "max         6.000000         6.000000    82.000000   364.000000    72.000000   \n",
       "\n",
       "       AgeFirstMarij  AgeRegMarij       SexAge  SexNumPartnLife  \\\n",
       "count    2339.000000  1086.000000  4464.000000      4600.000000   \n",
       "mean       17.050876    17.753223    17.433468        14.243261   \n",
       "std         3.944924     4.907613     3.695085        47.260997   \n",
       "min         1.000000     5.000000     9.000000         0.000000   \n",
       "25%        15.000000    15.000000    15.000000         2.000000   \n",
       "50%        16.000000    17.000000    17.000000         5.000000   \n",
       "75%        19.000000    19.000000    19.000000        12.000000   \n",
       "max        48.000000    52.000000    50.000000      1000.000000   \n",
       "\n",
       "       SexNumPartYear  \n",
       "count     3969.000000  \n",
       "mean         1.356513  \n",
       "std          2.709867  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max         69.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:13:32.145579500Z",
     "start_time": "2023-12-26T13:13:32.088566700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.11\n",
       "1       1.01\n",
       "2       1.63\n",
       "3       1.47\n",
       "4       1.19\n",
       "        ... \n",
       "7995    1.34\n",
       "7996    1.09\n",
       "7997    1.84\n",
       "7998    1.50\n",
       "7999    1.27\n",
       "Name: DirectChol, Length: 8000, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DirectChol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:21:28.029680600Z",
     "start_time": "2023-12-26T13:21:27.976029900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4697 entries, 0 to 7996\n",
      "Data columns (total 28 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           4697 non-null   int64  \n",
      " 1   Gender       4697 non-null   object \n",
      " 2   Age          4697 non-null   int64  \n",
      " 3   AgeDecade    4697 non-null   object \n",
      " 4   Race1        4697 non-null   object \n",
      " 5   HHIncome     4697 non-null   object \n",
      " 6   HHIncomeMid  4697 non-null   float64\n",
      " 7   Poverty      4697 non-null   float64\n",
      " 8   HomeRooms    4697 non-null   float64\n",
      " 9   HomeOwn      4697 non-null   object \n",
      " 10  Weight       4697 non-null   float64\n",
      " 11  Height       4697 non-null   float64\n",
      " 12  BMI          4697 non-null   float64\n",
      " 13  BMI_WHO      4697 non-null   object \n",
      " 14  Pulse        4697 non-null   float64\n",
      " 15  BPSysAve     4697 non-null   float64\n",
      " 16  BPDiaAve     4697 non-null   float64\n",
      " 17  BPSys1       4697 non-null   float64\n",
      " 18  BPDia1       4697 non-null   float64\n",
      " 19  BPSys2       4697 non-null   float64\n",
      " 20  BPDia2       4697 non-null   float64\n",
      " 21  BPSys3       4697 non-null   float64\n",
      " 22  BPDia3       4697 non-null   float64\n",
      " 23  DirectChol   4697 non-null   float64\n",
      " 24  UrineVol1    4697 non-null   float64\n",
      " 25  UrineFlow1   4697 non-null   float64\n",
      " 26  Diabetes     4697 non-null   object \n",
      " 27  PhysActive   4697 non-null   object \n",
      "dtypes: float64(18), int64(2), object(8)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12892\\3559155109.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 1500 nas\n",
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:25.110761900Z",
     "start_time": "2023-12-26T13:06:25.092762100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep for regression\n",
    "y_reg = newdf['DirectChol']\n",
    "x_reg = newdf.drop(columns=['DirectChol'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_reg, y_reg, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:27.218119100Z",
     "start_time": "2023-12-26T13:06:27.211118500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = {}  # containing scores and pipeline info\n",
    "\n",
    "# Score Helper Function\n",
    "def display_scores(model_score):\n",
    "    \"\"\"print the list of scores, the mean and the standard deviation\"\"\"\n",
    "    print(\"SCORES OF CROSS VALIDATION:\")\n",
    "    print(np.round(model_score, decimals=1))\n",
    "    print(\"MEAN SCORE: %0.1f\" % model_score.mean())\n",
    "    print(\"STD SCORE: %0.1f\\n\" % model_score.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:28.076527900Z",
     "start_time": "2023-12-26T13:06:28.070513800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lin_reg(x, y):\n",
    "    \"\"\"define model 1\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),  # select numeric attributes\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set toDo better to drop with our dataset?\n",
    "        (\"scaler\", StandardScaler()),  # scale to mean 0 and std 1 toDo: Maybe min_max_scaler?\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation toDo: is this necessary?\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output/lin_reg.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    joblib.dump(model_predictions, filename=\"output/lin_reg_poly_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output/lin_reg_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output/lin_reg_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:41.116737700Z",
     "start_time": "2023-12-26T13:06:28.879599400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:06:50.506166400Z",
     "start_time": "2023-12-26T13:06:50.481624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  2.55  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.34 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.4]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES: 48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "           name  value\n",
      "17    UrineVol1   0.00\n",
      "0            NR  -0.00\n",
      "11       BPSys1  -0.01\n",
      "12       BPDia1   0.01\n",
      "8         Pulse  -0.01\n",
      "41  HomeOwn_Own  -0.01 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "                    name         value\n",
      "39  HHIncome_75000-99999  5.533022e+10\n",
      "40   HHIncome_more 99999  6.346701e+10\n",
      "10              BPDiaAve  9.466151e+10\n",
      "15                BPSys3 -1.110090e+12\n",
      "13                BPSys2 -1.126322e+12\n",
      "9               BPSysAve  2.205099e+12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"output/lin_reg.pkl\")\n",
    "model_1_predictions = joblib.load(\"output/lin_reg_predictions.pkl\")\n",
    "model_1_scores = joblib.load(\"output/lin_reg_scores.pkl\")\n",
    "model_1_time = joblib.load(\"output/lin_reg_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_1_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_1_predictions)))\n",
    "\n",
    "scores[\"model_1\"] = [np.sqrt(-model_1_scores).mean(), model_1, \"Lin Reg\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_1\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_1_scores))\n",
    "\n",
    "print(\"USED FEATURES:\", model_1[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_1_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_1[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_1[\"regressor\"].coef_.flatten(),\n",
    "        \"abs_value\": np.abs(model_1[\"regressor\"].coef_).flatten()\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_1_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg_poly(x, y):\n",
    "    \"\"\"define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),  # select numeric attributes\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set toDo better to drop with our dataset?\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),  # add polynomial features\n",
    "        (\"scaler\", StandardScaler()),  # scale to mean 0 and std 1 toDo: Maybe min_max_scaler?\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation toDo: is this necessary?\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ])\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output/lin_reg_poly.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    joblib.dump(model_predictions, filename=\"output/lin_reg_poly_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output/lin_reg_poly_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output/lin_reg_poly_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_poly(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  4.29  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.35 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.3 0.3 0.4]\n",
      "MEAN SCORE: 0.3\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES: 239\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                     name  value\n",
      "104  HomeRooms UrineFlow1  -0.00\n",
      "209          UrineFlow1^2   0.00\n",
      "88      Poverty UrineVol1  -0.00\n",
      "21                 NR Age   0.01\n",
      "55          Age UrineVol1  -0.01\n",
      "133             BMI Pulse   0.01 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "                   name         value\n",
      "95   HomeRooms BPSysAve -5.562247e+10\n",
      "192       BPSys2 BPDia3  5.590543e+10\n",
      "10             BPSysAve -6.831852e+10\n",
      "163  BPSysAve UrineVol1  8.523152e+10\n",
      "162     BPSysAve BPDia3 -9.677565e+10\n",
      "165          BPDiaAve^2  9.745938e+10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = joblib.load(\"output/lin_reg_poly.pkl\")\n",
    "model_2_predictions = joblib.load(\"output/lin_reg_poly_predictions.pkl\")\n",
    "model_2_scores = joblib.load(\"output/lin_reg_poly_scores.pkl\")\n",
    "model_2_time = joblib.load(\"output/lin_reg_poly_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_2_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_2_predictions)))\n",
    "\n",
    "scores[\"model_2\"] = [np.sqrt(-model_2_scores).mean(), model_2, \"Lin Reg Poly\"]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_2\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_2_scores))\n",
    "\n",
    "print(\"USED FEATURES:\", model_2[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_2_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_2[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_2[\"regressor\"].coef_.flatten(),\n",
    "        \"abs_value\": np.abs(model_2[\"regressor\"].coef_).flatten()\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_2_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_2_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:00.260346400Z",
     "start_time": "2023-12-26T13:07:00.236279800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decicion_tree_reg(x, y):\n",
    "    \"\"\"define model 3\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # numeric feature preparation\n",
    "    pipeline_num = Pipeline([\n",
    "        (\"selector\", Selector(\"num features\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "    ])\n",
    "\n",
    "    # categorical feature preparation\n",
    "    pipeline_cat = Pipeline([\n",
    "        (\"selector\", Selector(\"cat features\")),  # select categorical attributes\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\", dtype=bool)),  # one-hot-encoding\n",
    "    ])\n",
    "\n",
    "    # combine numeric and categorical feature preparation\n",
    "    pipeline_full = FeatureUnion(transformer_list=[\n",
    "        (\"pipeline_num\", pipeline_num),\n",
    "        (\"pipeline_cat\", pipeline_cat),\n",
    "    ])\n",
    "\n",
    "    # set output to pandas, so we can use pandas tools again (e.g. for feature_names_in_)\n",
    "    pipeline_full.set_output(transform=\"pandas\")\n",
    "\n",
    "    # define full pipeline\n",
    "    base_model = Pipeline([\n",
    "        (\"pipeline_full\", pipeline_full),\n",
    "        (\"regressor\", DecisionTreeRegressor(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"regressor__max_depth\": [8],\n",
    "            \"regressor__min_samples_leaf\": [0.0009],  # [0.0008, 0.0009, 0.001],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, scoring=\"neg_root_mean_squared_error\", n_jobs=-1) #ToDo: how does gS work?\n",
    "\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_scores = cross_val_score(model_new, x, y, scoring=\"neg_mean_squared_error\", cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output/decicion_tree.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output/decicion_tree_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output/decicion_tree_predictions.pkl\")\n",
    "    joblib.dump(model_scores, filename=\"output/decicion_tree_scores.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output/decicion_tree_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:09.003828100Z",
     "start_time": "2023-12-26T13:07:05.541744Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  4.2  sec\n",
      "\n",
      "RMSE: 0.3\n",
      "\n",
      "VALUE FOR COMPARISON: CV RMSE 0.38 \n",
      "\n",
      "SCORES OF CROSS VALIDATION:\n",
      "[0.4 0.4 0.4]\n",
      "MEAN SCORE: 0.4\n",
      "STD SCORE: 0.0\n",
      "\n",
      "USED FEATURES:  48\n",
      "FEATURE VALUE IMPORTANCE:\n",
      "LOWEST ABS SCORE:\n",
      "                    name  value\n",
      "23      AgeDecade_ 50-59    0.0\n",
      "32  HHIncome_15000-19999    0.0\n",
      "31  HHIncome_10000-14999    0.0\n",
      "28           Race1_Other    0.0\n",
      "27         Race1_Mexican    0.0\n",
      "26        Race1_Hispanic    0.0 \n",
      "\n",
      "HIGHEST ABS SCORE:\n",
      "           name  value\n",
      "6        Height   0.04\n",
      "18   UrineFlow1   0.05\n",
      "19  Gender_male   0.06\n",
      "7           BMI   0.08\n",
      "1           Age   0.10\n",
      "5        Weight   0.31 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "regressor__max_depth: 8\n",
      "regressor__min_samples_leaf: 0.0009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decicion_tree_reg(X_train, y_train)\n",
    "model_3 = joblib.load(\"output/decicion_tree.pkl\")\n",
    "\n",
    "with open(\"output/decicion_tree_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions = joblib.load(\"output/decicion_tree_predictions.pkl\")\n",
    "model_3_scores = joblib.load(\"output/decicion_tree_scores.pkl\")\n",
    "model_3_time = joblib.load(\"output/decicion_tree_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"RMSE: %0.1f\\n\" % np.sqrt(mean_squared_error(y_train, model_3_predictions)))\n",
    "\n",
    "scores[\"model_3\"] = [np.sqrt(-model_3_scores).mean(), model_3]\n",
    "print(\"VALUE FOR COMPARISON: CV RMSE\", round(scores[\"model_3\"][0], 2), \"\\n\")\n",
    "display_scores(np.sqrt(-model_3_scores))\n",
    "\n",
    "print(\"USED FEATURES: \", model_3[\"regressor\"].n_features_in_)\n",
    "\n",
    "model_3_feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": model_3[\"regressor\"].feature_names_in_,\n",
    "        \"value\": model_3[\"regressor\"].feature_importances_,\n",
    "        \"abs_value\": np.abs(model_3[\"regressor\"].feature_importances_)\n",
    "    }).sort_values(by=\"abs_value\")\n",
    "\n",
    "print(\"FEATURE VALUE IMPORTANCE:\")\n",
    "print(\"LOWEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.head(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "print(\"HIGHEST ABS SCORE:\")\n",
    "print(round(model_3_feature_importances.tail(6)[[\"name\", \"value\"]], 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T16:05:12.458783400Z",
     "start_time": "2023-12-23T16:05:12.445775100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SVR_class(x, y):\n",
    "    \"\"\"Define model 3\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", SVC()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__kernel\": [\"rbf\"],\n",
    "            \"classifier__degree\": [2],  # [2, 3],\n",
    "            \"classifier__C\": [10],  # [1, 1e-1, 1e-2, 10, 100],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    with open(\"output/SVR_class.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model, ff)\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output/SVR_class_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output/SVR_class_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"output/SVR_class_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output/SVR_class_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T16:05:32.856264400Z",
     "start_time": "2023-12-23T16:05:32.234617200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 369, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 330, in _validate_input\n    raise new_ve from None\nValueError: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'male'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSVR_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model_3 \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVR_class.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVR_class_best_params.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m, in \u001b[0;36mSVR_class\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m model_param \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# softmax regression\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     }\n\u001b[0;32m     21\u001b[0m ]\n\u001b[0;32m     23\u001b[0m model_gs \u001b[38;5;241m=\u001b[39m GridSearchCV(base_model, model_param, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel_gs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m model_gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     28\u001b[0m model_best_params \u001b[38;5;241m=\u001b[39m model_gs\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 369, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 330, in _validate_input\n    raise new_ve from None\nValueError: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'male'\n"
     ]
    }
   ],
   "source": [
    "SVR_class(X_train, y_train)\n",
    "\n",
    "model_3 = joblib.load(\"output/SVR_class.pkl\")\n",
    "\n",
    "with open(\"output/SVR_class_best_params.pkl\", 'rb') as f:\n",
    "    model_3_best_params = pickle.load(f)\n",
    "\n",
    "model_3_predictions = joblib.load(\"output/SVR_class_predictions.pkl\")\n",
    "model_3_predictions_cv = joblib.load(\"output/SVR_class_predictions_cv.pkl\")\n",
    "model_3_time = joblib.load(\"output/SVR_class_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_3_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train, model_3_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train, model_3_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train, model_3_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train, model_3_predictions_cv))\n",
    "\n",
    "model_3_score = f1_score(y_train, model_3_predictions_cv, average=\"weighted\")\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_3_score, 2), \"\\n\")\n",
    "scores[\"model_3\"] = [model_3_score, model_3]\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_3_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:07:41.210174500Z",
     "start_time": "2023-12-26T13:07:41.192161100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_f_class(x, y):\n",
    "    \"\"\"Define model 4\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", RandomForestClassifier(random_state=123)),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__n_estimators\": [600],  # [10, 50, 100, 200, 400, 600, 800],\n",
    "            \"classifier__max_depth\": [20],  # [None, 5, 10, 20, 30, 50],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"output/random_f_class.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"output/random_f_class_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"output/random_f_class_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"output/random_f_class_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"output/random_f_class_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:12:45.049839300Z",
     "start_time": "2023-12-26T13:12:45.012435600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeDecade</th>\n",
       "      <th>Race1</th>\n",
       "      <th>HHIncome</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>HomeOwn</th>\n",
       "      <th>...</th>\n",
       "      <th>BPDia1</th>\n",
       "      <th>BPSys2</th>\n",
       "      <th>BPDia2</th>\n",
       "      <th>BPSys3</th>\n",
       "      <th>BPDia3</th>\n",
       "      <th>DirectChol</th>\n",
       "      <th>UrineVol1</th>\n",
       "      <th>UrineFlow1</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9217</td>\n",
       "      <td>male</td>\n",
       "      <td>44</td>\n",
       "      <td>40-49</td>\n",
       "      <td>White</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.745</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919</td>\n",
       "      <td>female</td>\n",
       "      <td>59</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Black</td>\n",
       "      <td>45000-54999</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.842</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5903</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>40-49</td>\n",
       "      <td>White</td>\n",
       "      <td>0-4999</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.613</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9798</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Black</td>\n",
       "      <td>65000-74999</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2863</td>\n",
       "      <td>male</td>\n",
       "      <td>42</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Black</td>\n",
       "      <td>25000-34999</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.457</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>6258</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Black</td>\n",
       "      <td>more 99999</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>97</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>30-39</td>\n",
       "      <td>White</td>\n",
       "      <td>more 99999</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>313.0</td>\n",
       "      <td>3.817</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>5858</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>10-19</td>\n",
       "      <td>White</td>\n",
       "      <td>more 99999</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Own</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>7383</td>\n",
       "      <td>female</td>\n",
       "      <td>39</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>10000-14999</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7764</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>20-29</td>\n",
       "      <td>White</td>\n",
       "      <td>20000-24999</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.970</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4697 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NR  Gender  Age AgeDecade     Race1     HHIncome  HHIncomeMid  \\\n",
       "0     9217    male   44     40-49     White  25000-34999      30000.0   \n",
       "2      919  female   59     50-59     Black  45000-54999      50000.0   \n",
       "3     5903  female   40     40-49     White       0-4999       2500.0   \n",
       "6     9798    male   33     30-39     Black  65000-74999      70000.0   \n",
       "9     2863    male   42     40-49     Black  25000-34999      30000.0   \n",
       "...    ...     ...  ...       ...       ...          ...          ...   \n",
       "7991  6258    male   14     10-19     Black   more 99999     100000.0   \n",
       "7992    97  female   35     30-39     White   more 99999     100000.0   \n",
       "7993  5858    male   14     10-19     White   more 99999     100000.0   \n",
       "7994  7383  female   39     30-39  Hispanic  10000-14999      12500.0   \n",
       "7996  7764  female   27     20-29     White  20000-24999      22500.0   \n",
       "\n",
       "      Poverty  HomeRooms HomeOwn  ...  BPDia1  BPSys2  BPDia2 BPSys3  BPDia3  \\\n",
       "0        1.31        8.0     Own  ...    72.0   114.0    70.0  110.0    72.0   \n",
       "2        4.62        7.0     Own  ...    64.0   106.0    66.0  102.0    74.0   \n",
       "3        0.12        7.0     Own  ...    80.0   116.0    76.0  114.0    74.0   \n",
       "6        4.76        4.0     Own  ...    68.0   102.0    72.0  100.0    70.0   \n",
       "9        1.02        6.0     Own  ...   110.0   146.0   102.0  144.0   106.0   \n",
       "...       ...        ...     ...  ...     ...     ...     ...    ...     ...   \n",
       "7991     3.85        6.0    Rent  ...    62.0   112.0    60.0  110.0    66.0   \n",
       "7992     4.54        4.0    Rent  ...    70.0   104.0    66.0  108.0    64.0   \n",
       "7993     5.00       10.0     Own  ...    44.0   108.0    60.0  110.0    46.0   \n",
       "7994     0.73        4.0    Rent  ...    86.0   122.0    86.0  128.0    82.0   \n",
       "7996     0.89        7.0    Rent  ...    76.0   120.0    78.0  128.0    78.0   \n",
       "\n",
       "      DirectChol  UrineVol1  UrineFlow1  Diabetes  PhysActive  \n",
       "0           1.11      331.0       0.745        No         Yes  \n",
       "2           1.63       64.0       0.842        No          No  \n",
       "3           1.47       46.0       0.613        No          No  \n",
       "6           1.37       49.0       0.790        No          No  \n",
       "9           0.85      134.0       1.457        No          No  \n",
       "...          ...        ...         ...       ...         ...  \n",
       "7991        1.78      201.0       0.659        No         Yes  \n",
       "7992        1.81      313.0       3.817        No         Yes  \n",
       "7993        1.71      131.0       0.645        No         Yes  \n",
       "7994        1.66       43.0       0.439        No          No  \n",
       "7996        1.09       64.0       0.970        No         Yes  \n",
       "\n",
       "[4697 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:32.048348200Z",
     "start_time": "2023-12-26T13:36:31.964470100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5142 entries, 0 to 7997\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   NR           5142 non-null   int64  \n",
      " 1   Age          5142 non-null   int64  \n",
      " 2   HHIncomeMid  5142 non-null   float64\n",
      " 3   Poverty      5142 non-null   float64\n",
      " 4   HomeRooms    5142 non-null   float64\n",
      " 5   Weight       5142 non-null   float64\n",
      " 6   Height       5142 non-null   float64\n",
      " 7   BMI          5142 non-null   float64\n",
      " 8   Pulse        5142 non-null   float64\n",
      " 9   BPSysAve     5142 non-null   float64\n",
      " 10  BPDiaAve     5142 non-null   float64\n",
      " 11  BPSys1       5142 non-null   float64\n",
      " 12  BPDia1       5142 non-null   float64\n",
      " 13  BPSys2       5142 non-null   float64\n",
      " 14  BPDia2       5142 non-null   float64\n",
      " 15  BPSys3       5142 non-null   float64\n",
      " 16  BPDia3       5142 non-null   float64\n",
      " 17  DirectChol   5142 non-null   float64\n",
      " 18  UrineVol1    5142 non-null   float64\n",
      " 19  UrineFlow1   5142 non-null   float64\n",
      " 20  Diabetes     5142 non-null   float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 883.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12892\\3168420372.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('project_1_train.csv')\n",
    "#Applying the condition, but leave nan for now\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'Yes', 0, inplace=True)\n",
    "df['Diabetes'].mask(df['Diabetes'] == 'No', 1, inplace=True)\n",
    "df[\"Diabetes\"] = df[\"Diabetes\"].astype(float)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df = df.select_dtypes(include=numerics)\n",
    "\n",
    "\n",
    "\n",
    "max_number_of_nas = 1500\n",
    "newdf = df.loc[:, (df.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "newdf.dropna(inplace=True)\n",
    "newdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:46.318029200Z",
     "start_time": "2023-12-26T13:36:46.295413400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_clas = newdf['Diabetes']\n",
    "\n",
    "x_clas = newdf.drop(columns=['Diabetes'])\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(x_clas, y_clas, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:36:54.833372500Z",
     "start_time": "2023-12-26T13:36:54.797810700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>Age</th>\n",
       "      <th>HHIncomeMid</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>HomeRooms</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>BPSysAve</th>\n",
       "      <th>BPDiaAve</th>\n",
       "      <th>BPSys1</th>\n",
       "      <th>BPDia1</th>\n",
       "      <th>BPSys2</th>\n",
       "      <th>BPDia2</th>\n",
       "      <th>BPSys3</th>\n",
       "      <th>BPDia3</th>\n",
       "      <th>DirectChol</th>\n",
       "      <th>UrineVol1</th>\n",
       "      <th>UrineFlow1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>3897</td>\n",
       "      <td>50</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>108.9</td>\n",
       "      <td>180.5</td>\n",
       "      <td>33.43</td>\n",
       "      <td>76.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>291</td>\n",
       "      <td>65</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>175.5</td>\n",
       "      <td>22.01</td>\n",
       "      <td>82.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>5526</td>\n",
       "      <td>24</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.6</td>\n",
       "      <td>176.4</td>\n",
       "      <td>29.80</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>2429</td>\n",
       "      <td>64</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>9723</td>\n",
       "      <td>57</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>169.3</td>\n",
       "      <td>24.70</td>\n",
       "      <td>48.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>407</td>\n",
       "      <td>22</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.8</td>\n",
       "      <td>162.0</td>\n",
       "      <td>24.31</td>\n",
       "      <td>62.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>8296</td>\n",
       "      <td>73</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.9</td>\n",
       "      <td>169.9</td>\n",
       "      <td>28.70</td>\n",
       "      <td>78.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>5615</td>\n",
       "      <td>50</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>94.2</td>\n",
       "      <td>175.5</td>\n",
       "      <td>30.60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>6515</td>\n",
       "      <td>22</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>154.9</td>\n",
       "      <td>31.70</td>\n",
       "      <td>70.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>2117</td>\n",
       "      <td>38</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>163.9</td>\n",
       "      <td>24.87</td>\n",
       "      <td>64.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4113 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NR  Age  HHIncomeMid  Poverty  HomeRooms  Weight  Height    BMI  \\\n",
       "5211  3897   50      87500.0     3.63       10.0   108.9   180.5  33.43   \n",
       "1475   291   65     100000.0     5.00        7.0    67.8   175.5  22.01   \n",
       "6290  5526   24      50000.0     2.33        4.0    92.6   176.4  29.80   \n",
       "7967  2429   64     100000.0     5.00       10.0    98.0   176.0  31.64   \n",
       "3271  9723   57      70000.0     3.13        5.0    70.8   169.3  24.70   \n",
       "...    ...  ...          ...      ...        ...     ...     ...    ...   \n",
       "2412   407   22      60000.0     1.39        5.0    63.8   162.0  24.31   \n",
       "6275  8296   73      87500.0     2.20        5.0    82.9   169.9  28.70   \n",
       "2020  5615   50      87500.0     5.00        7.0    94.2   175.5  30.60   \n",
       "5340  6515   22      30000.0     1.67        5.0    76.1   154.9  31.70   \n",
       "5530  2117   38     100000.0     4.99        4.0    66.8   163.9  24.87   \n",
       "\n",
       "      Pulse  BPSysAve  BPDiaAve  BPSys1  BPDia1  BPSys2  BPDia2  BPSys3  \\\n",
       "5211   76.0     125.0      72.0   124.0    70.0   128.0    72.0   122.0   \n",
       "1475   82.0     114.0      53.0   112.0    54.0   114.0    52.0   114.0   \n",
       "6290   70.0     102.0      56.0   102.0    58.0   102.0    56.0   102.0   \n",
       "7967   66.0     116.0      67.0   114.0    64.0   116.0    66.0   116.0   \n",
       "3271   48.0     113.0      65.0   114.0    66.0   116.0    66.0   110.0   \n",
       "...     ...       ...       ...     ...     ...     ...     ...     ...   \n",
       "2412   62.0     119.0      49.0   118.0    46.0   120.0    46.0   118.0   \n",
       "6275   78.0     123.0      65.0   124.0    62.0   126.0    62.0   120.0   \n",
       "2020   78.0     110.0      79.0   112.0    84.0   108.0    80.0   112.0   \n",
       "5340   70.0     119.0      51.0   116.0    50.0   120.0    48.0   118.0   \n",
       "5530   64.0     107.0      70.0   102.0    70.0   106.0    70.0   108.0   \n",
       "\n",
       "      BPDia3  DirectChol  UrineVol1  UrineFlow1  \n",
       "5211    72.0        1.06       64.0       0.753  \n",
       "1475    54.0        1.60       21.0       0.368  \n",
       "6290    56.0        1.06       33.0       0.068  \n",
       "7967    68.0        0.93       67.0       0.677  \n",
       "3271    64.0        1.14       97.0       0.890  \n",
       "...      ...         ...        ...         ...  \n",
       "2412    52.0        2.12      242.0       1.485  \n",
       "6275    68.0        1.06       23.0       0.299  \n",
       "2020    78.0        0.85       56.0       0.339  \n",
       "5340    54.0        1.34       54.0       0.551  \n",
       "5530    70.0        1.53      212.0       0.951  \n",
       "\n",
       "[4113 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:37:18.665601800Z",
     "start_time": "2023-12-26T13:36:57.260670600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_f_class(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:41:33.642213700Z",
     "start_time": "2023-12-26T13:41:33.382322500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  82.93  sec\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "[[ 348    0]\n",
      " [   0 3765]] \n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[ 103  245]\n",
      " [  11 3754]] \n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       348\n",
      "         1.0       1.00      1.00      1.00      3765\n",
      "\n",
      "    accuracy                           1.00      4113\n",
      "   macro avg       1.00      1.00      1.00      4113\n",
      "weighted avg       1.00      1.00      1.00      4113\n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.30      0.45       348\n",
      "         1.0       0.94      1.00      0.97      3765\n",
      "\n",
      "    accuracy                           0.94      4113\n",
      "   macro avg       0.92      0.65      0.71      4113\n",
      "weighted avg       0.94      0.94      0.92      4113\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.92 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__max_depth: 20\n",
      "classifier__n_estimators: 600\n",
      "pca__n_components: 0.9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "model_4 = joblib.load(\"random_f_class.pkl\")\n",
    "\n",
    "with open(\"random_f_class_best_params.pkl\", 'rb') as f:\n",
    "    model_4_best_params = pickle.load(f)\n",
    "\n",
    "model_4_predictions = joblib.load(\"random_f_class_predictions.pkl\")\n",
    "model_4_predictions_cv = joblib.load(\"random_f_class_predictions_cv.pkl\")\n",
    "model_4_time = joblib.load(\"random_f_class_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_4_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_4_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_4_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_4_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_4_predictions_cv))\n",
    "\n",
    "model_4_score = f1_score(y_train_c, model_4_predictions_cv, average=\"weighted\")\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_4_score, 2), \"\\n\")\n",
    "scores[\"model_4\"] = [model_4_score, model_4]\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_4_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:51:56.241592400Z",
     "start_time": "2023-12-26T13:51:56.196566300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def run_model_2(x, y):\n",
    "    \"\"\"Define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "    # possible fine-tuned parameters\n",
    "    model_param = [\n",
    "        # binary fit for each label\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__multi_class\": [\"ovr\"],  # binary fit for each label\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"lbfgs\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        },\n",
    "        # softmax regression\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],\n",
    "            \"classifier__multi_class\": [\"multinomial\"],  # softmax regression\n",
    "            \"classifier__penalty\": [\"l2\"],\n",
    "            \"classifier__solver\": [\"saga\"],\n",
    "            \"classifier__C\": [0.1],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # store model\n",
    "    joblib.dump(model, filename=\"log_reg_cl.pkl\")\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"log_reg_cl_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"log_reg_cl_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"log_reg_cl_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"log_reg_cl_time.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T13:53:20.362279800Z",
     "start_time": "2023-12-26T13:53:20.156575300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  0.17  sec\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "[[   0  348]\n",
      " [   0 3765]] \n",
      "\n",
      "CROSS VALIDATION CONFUSION MATRIX:\n",
      "[[   0  348]\n",
      " [   0 3765]] \n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       348\n",
      "         1.0       0.92      1.00      0.96      3765\n",
      "\n",
      "    accuracy                           0.92      4113\n",
      "   macro avg       0.46      0.50      0.48      4113\n",
      "weighted avg       0.84      0.92      0.87      4113\n",
      "\n",
      "CROSS CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       348\n",
      "         1.0       0.92      1.00      0.96      3765\n",
      "\n",
      "    accuracy                           0.92      4113\n",
      "   macro avg       0.46      0.50      0.48      4113\n",
      "weighted avg       0.84      0.92      0.87      4113\n",
      "\n",
      "VALUE FOR COMPARISON: WEIGHTED F1_SCORE: 0.87 \n",
      "\n",
      "OPTIMAL PARAMETERS:\n",
      "classifier__C: 0.1\n",
      "classifier__multi_class: ovr\n",
      "classifier__penalty: l2\n",
      "classifier__solver: lbfgs\n",
      "pca__n_components: 0.9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\johan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_model_2(X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "model_2 = joblib.load(\"log_reg_cl.pkl\")\n",
    "\n",
    "with open(\"log_reg_cl_best_params.pkl\", 'rb') as f:\n",
    "    model_2_best_params = pickle.load(f)\n",
    "\n",
    "model_2_predictions = joblib.load(\"log_reg_cl_predictions.pkl\")\n",
    "model_2_predictions_cv = joblib.load(\"log_reg_cl_predictions_cv.pkl\")\n",
    "model_2_time = joblib.load(\"log_reg_cl_time.pkl\")\n",
    "\n",
    "print(\"TIME: \", round(model_2_time, 2), \" sec\\n\")\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_2_predictions), \"\\n\")\n",
    "\n",
    "print(\"CROSS VALIDATION CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_train_c, model_2_predictions_cv), \"\\n\")\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_2_predictions))\n",
    "\n",
    "print(\"CROSS CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_train_c, model_2_predictions_cv))\n",
    "\n",
    "model_2_score = f1_score(y_train_c, model_2_predictions_cv, average=\"weighted\")\n",
    "scores[\"model_2\"] = [model_2_score, model_2]\n",
    "print(\"VALUE FOR COMPARISON: WEIGHTED F1_SCORE:\", round(model_2_score, 2), \"\\n\")\n",
    "\n",
    "print(\"OPTIMAL PARAMETERS:\")\n",
    "for param, value in model_2_best_params.items():\n",
    "    print(param, \": \", value, sep=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
