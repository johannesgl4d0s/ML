{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:08:34.848304Z",
     "start_time": "2024-01-19T10:08:07.091443500Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "class MyDynamicKerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Custom classifier that wraps a dynamic Keras model for use with scikit-learn pipelines.\n",
    "    This wrapper is necessary because sometimes (e.g. when using pca in pipeline) the input shape is not clear apriori\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, epochs=None, batch_size=None, verbose=0, optimizer=\"adam\", loss=None, metrics=None, cnn=False, cnn_shape_list=None):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "        self.cnn = cnn\n",
    "        self.cnn_shape_list = cnn_shape_list\n",
    "        self.keras_model = None\n",
    "        self.history = None\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"fits the parameter\"\"\"\n",
    "\n",
    "        # convert y to numpy array and set classes_\n",
    "        y = np.array(y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            if self.cnn:\n",
    "                x_new = x.reshape(self.cnn_shape_list)\n",
    "                self.keras_model = self.model(input_shape=x_new.shape[1:])\n",
    "                self.keras_model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "                self.history = self.keras_model.fit(x_new, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "            else:\n",
    "                self.keras_model = self.model(input_shape=(x.shape[1],))\n",
    "                self.keras_model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "                self.history = self.keras_model.fit(x, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict using the Keras model.\"\"\"\n",
    "\n",
    "        if self.keras_model is None:\n",
    "            raise Exception(\"The model has not been fitted yet!\")\n",
    "        elif self.cnn:\n",
    "            x_new = x.reshape(self.cnn_shape_list)\n",
    "            probabilities = self.keras_model.predict(x_new, verbose=self.verbose)\n",
    "        else:\n",
    "            probabilities = self.keras_model.predict(x, verbose=self.verbose)\n",
    "\n",
    "        if probabilities.shape[1] == 1:\n",
    "            # Use 0.5 as the threshold to convert probabilities to binary labels\n",
    "            return (probabilities > 0.5).astype('int32')\n",
    "        else:\n",
    "            # Use argmax for multi-class problems\n",
    "            return probabilities.argmax(axis=1)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get parameters for this estimator.\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"verbose\": self.verbose,\n",
    "            \"optimizer\": self.optimizer,\n",
    "            \"loss\": self.loss,\n",
    "            \"metrics\": self.metrics,\n",
    "            \"cnn\": self.cnn,\n",
    "            \"cnn_shape_list\": self.cnn_shape_list,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set parameters for this estimator.\"\"\"\n",
    "        valid_params = self.get_params(deep=True)\n",
    "        for parameter, value in params.items():\n",
    "            if parameter in valid_params:\n",
    "                setattr(self, parameter, value)\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:09:26.831897500Z",
     "start_time": "2024-01-19T10:09:26.791457400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def DNN_gridsearch(x, y):\n",
    "    \"\"\"Define model 1\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    def create_model(input_shape=None):\n",
    "        \"\"\"Define classifier for model 1\"\"\"\n",
    "        keras_model = tf.keras.models.Sequential()\n",
    "        keras_model.add(tf.keras.layers.Dense(units=10, input_shape=input_shape))\n",
    "        keras_model.add(tf.keras.layers.Dense(units=8))\n",
    "        keras_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "        return keras_model\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        # binary_crossentropy is the same as for logistic regression\n",
    "        (\"keras\", MyDynamicKerasClassifier(model=create_model, epochs=150, batch_size=32, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])),\n",
    "    ])\n",
    "\n",
    "    model_param = [\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],  # [0.85, 0.9, 0.95, 0.99, 0.999]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # we cannot save a pipeline with keras, so we have to save both separately\n",
    "    model.named_steps[\"keras\"].keras_model.save(\"model_1_keras\")  # save only the Keras model\n",
    "    model.steps.pop(-1)  # removing the keras step (last step)\n",
    "    joblib.dump(model, filename=\"model_1_without_keras.pkl\")  # save pipeline without Keras model\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"model_1_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"model_1_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"model_1_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"model_1_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T10:12:59.322743800Z",
     "start_time": "2024-01-19T10:12:59.294136900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def run_model_2(x, y):\n",
    "    \"\"\"Define model 2\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    def create_model(input_shape=None):\n",
    "        \"\"\"Define classifier for model 2\"\"\"\n",
    "        keras_model = tf.keras.models.Sequential()\n",
    "        keras_model.add(tf.keras.layers.Dense(units=20, input_shape=input_shape))\n",
    "        keras_model.add(tf.keras.layers.Dense(units=15))\n",
    "        # softmax is the same as for logistic regression\n",
    "        keras_model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "        return keras_model\n",
    "\n",
    "    base_model = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),  # missing values are replaced by column median of train_set\n",
    "        (\"scaler\", MinMaxScaler()),  # scale to interval [0, 1]\n",
    "        (\"pca\", PCA()),\n",
    "        # sparse_categorical_crossentropy is used when labels are integers (e.g. label1=5, label2=3, ...)\n",
    "        # categorical_crossentropy is used when labels are one-hot-encoded (e.g. label1=[0,0,0,0,0,1,0,0,0,0], label2=[0,0,0,1,0,0,0,0,0,0], ...)\n",
    "        (\"keras\", MyDynamicKerasClassifier(model=create_model, epochs=150, batch_size=32, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])),\n",
    "    ])\n",
    "\n",
    "    model_param = [\n",
    "        {\n",
    "            \"pca__n_components\": [0.9],  # [0.85, 0.9, 0.95, 0.99, 0.999]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model_gs = GridSearchCV(base_model, model_param, cv=10, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "\n",
    "    model_gs.fit(x, y)\n",
    "\n",
    "    model = model_gs.best_estimator_\n",
    "\n",
    "    model_best_params = model_gs.best_params_\n",
    "\n",
    "    model_predictions = model.predict(x)\n",
    "\n",
    "    # attention: it is not allowed to use a fitted model (like model) in cross_val_predict because information gets through\n",
    "    # unfitted model (clone(model)) is used for cross validation\n",
    "\n",
    "    model_new = clone(model)\n",
    "    model_predictions_cv = cross_val_predict(model_new, x, y, cv=3, n_jobs=-1)\n",
    "\n",
    "    end = time.time()\n",
    "    model_time = end - start\n",
    "\n",
    "    # we cannot save a pipeline with keras, so we have to save both separately\n",
    "    model.named_steps[\"keras\"].keras_model.save(\"model_2_keras\")  # save only the Keras model\n",
    "    model.steps.pop(-1)  # removing the keras step (last step)\n",
    "    joblib.dump(model, filename=\"model_2_without_keras.pkl\")  # save pipeline without Keras model\n",
    "\n",
    "    # use the following to store the best params of grid search\n",
    "    with open(\"model_2_best_params.pkl\", \"wb\") as ff:\n",
    "        pickle.dump(model_best_params, ff)\n",
    "\n",
    "    joblib.dump(model_predictions, filename=\"model_2_predictions.pkl\")\n",
    "    joblib.dump(model_predictions_cv, filename=\"model_2_predictions_cv.pkl\")\n",
    "    joblib.dump(model_time, filename=\"model_2_time.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
